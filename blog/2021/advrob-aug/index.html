<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <script>let thunk=()=>{let e=e=>e.trim(),t=e=>e.innerText,n=e=>{let t=e.split(" "),n=t.slice(0,-1).join(" ");return[t.at(-1),n]},a=Array.from(document.getElementsByClassName("author")).map(t).map(e).map(n),i=a[0][0],r=(Array.from(document.getElementsByClassName("affiliation")).filter(e=>"P"===e.nodeName).map(t).map(e),"Reassessing adversarial training with fixed data augmentation"),m="2021",o="June 24, 2025";{let e=a.map(e=>`${e[0]}, ${e[1]}`).join(" and "),t=`\n@article{${(i+m+r.split(" ").slice(0,3).join("")).replace(" ","").replace(/[\p{P}$+<=>^`|~]/gu,"").toLowerCase().trim()},\n  author = {${e}},\n  title = {${r}},\n  year = {${m}},\n  note = {Accessed ${o}},\n  url  = {${window.location.href}}\n}\n  `.trim();document.getElementById("bibtex-box").innerText=t}};document.addEventListener("readystatechange",function(){"complete"===document.readyState&&thunk()});</script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Reassessing adversarial training with fixed data augmentation | Anshuman Suri </title> <meta name="author" content="Anshuman Suri"> <meta name="description" content="A recent bug discovery on Pytorch+Numpy got me thinking- how much does this bug impact adversarial robustness?"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.css" integrity="sha256-uRX+PiRTR4ysKFRCykT8HLuRCub26LgXJZym3Yeom1c=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%90%BF%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://anshumansuri.com/blog/2021/advrob-aug/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <d-front-matter> <script async type="text/json">
      {
            "title": "Reassessing adversarial training with fixed data augmentation",
            "description": "A recent bug discovery on Pytorch+Numpy got me thinking- how much does this bug impact adversarial robustness?",
            "published": "June 24, 2021",
            "authors": [
              
              {
                "author": "Anshuman Suri",
                "authorURL": "https://anshumansuri.com/",
                "affiliations": [
                  {
                    "name": "University of Virginia",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Anshuman</span> Suri </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news </a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks </a> </li> <li class="nav-item "> <a class="nav-link" href="/service/">service </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Reassessing adversarial training with fixed data augmentation</h1> <p>A recent bug discovery on Pytorch+Numpy got me thinking- how much does this bug impact adversarial robustness?</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#overview">Overview</a> </div> <div> <a href="#experiments">Experiments</a> </div> <div> <a href="#"></a> </div> <ul> <li> <a href="#standard-training">Standard Training</a> </li> <li> <a href="#adversarial-training">Adversarial Training</a> </li> </ul> <div> <a href="#takeaway">Takeaway</a> </div> </nav> </d-contents> <h2 id="overview">Overview</h2> <p>A couple months ago, a <a href="https://www.reddit.com/r/MachineLearning/comments/mocpgj/p_using_pytorch_numpy_a_bug_that_plagues/" rel="external nofollow noopener" target="_blank">post on Reddit</a> highlighted a bug in PyTorch + NumPy that affects how data augmentation works (see image above). Knowing nearly all of my projects use this combination, I read through the <a href="https://tanelp.github.io/posts/a-bug-that-plagues-thousands-of-open-source-ml-projects/" rel="external nofollow noopener" target="_blank">linked blog</a> by Tanel Pärnamaa to see what it was all about. I was a bit shocked that it took our community this long to notice a bug this severe! Nearly all data-loaders use more than one worker. Unfortunately, not many people (clearly, since it took us all so long to notice this bug) sit down to debug data augmentation at this level within their ML pipeline.</p> <p>Reading through this bug, I remembered how (proper) data-augmentation had been proposed as a means to reduce robust overfitting by authors at DeepMind <d-cite key="rebuffi2021fixing"> </d-cite>. This paper got me thinking: “Could fixing this augmentation bug and rerunning adversarial training lead to gains in robustness?”. Curious to see the impact of fixing this data augmentation bug, I decided to run some experiments of my own. You can head over to <a href="https://github.com/iamgroot42/aug_robust_blogpost" rel="external nofollow noopener" target="_blank">the repository</a> and run them yourself if you want.</p> <h2 id="experiments">Experiments</h2> <p>I chose the CIFAR-10 dataset: small enough to iterate experiments fast and challenging enough to observe performance gains.</p> <h3 id="standard-training">Standard Training</h3> <p>Interestingly, standard training with the fixed data-augmentation pipeline <strong>hurt</strong> performance a bit, compared to using faulty augmentation:</p> <table> <thead> <tr> <th>Model</th> <th>Standard Accuracy (%)</th> <th>Robust Accuracy (ε = 8/255) (%)</th> </tr> </thead> <tbody> <tr> <td>Standard</td> <td>89.140</td> <td>0.000</td> </tr> <tr> <td>Standard (augmentation)</td> <td>94.720</td> <td>0.000</td> </tr> <tr> <td>Standard (fixed augmentation)</td> <td>94.620</td> <td>0.000</td> </tr> </tbody> </table> <h3 id="adversarial-training">Adversarial Training</h3> <p>Not thinking much about the 0.1% performance drop (probably statistical noise, right?), I ran adversarial training with \(L_\infty\) robustness (\(\epsilon=\frac{8}{255}\)):</p> <table> <thead> <tr> <th>Model</th> <th>Standard Accuracy (%)</th> <th>Robust Accuracy (ε = 8/255) (%)</th> <th>Robust Accuracy (ε = 16/255) (%)</th> </tr> </thead> <tbody> <tr> <td>Robust</td> <td>79.520</td> <td>44.370</td> <td>15.680</td> </tr> <tr> <td>Robust (augmentation)</td> <td>86.320</td> <td>51.400</td> <td>17.480</td> </tr> <tr> <td>Robust (fixed augmentation)</td> <td>86.730</td> <td>51.880</td> <td>17.570</td> </tr> </tbody> </table> <p>As visible here, there’s an absolute 0.4% performance gain for $\epsilon=\frac{8}{255}$, and 0.09% performance gain for $\epsilon=\frac{4}{255}$, when using the fixed augmentation pipeline. Although the 0.09% here is not very significant, the 0.4% improvement seems non-trivial. This improvement is especially significant compared to the kind of performance differences reported on <a href="https://robustbench.github.io/#div_cifar10_Linf_heading" rel="external nofollow noopener" target="_blank">benchmarks</a> for this dataset. Additionally, accuracy on clean data sees an improvement as well: absolute 0.41% change.</p> <p>Not wanting to make any claims based on experiments on just the $L_\infty$ norm, I reran the same set of experiments for the \(L_2\) norm (\(\epsilon=1\)).</p> <table> <thead> <tr> <th>Model</th> <th>Standard Accuracy (%)</th> <th>Robust Accuracy (%), ε = 0.5</th> <th>Robust Accuracy (%), ε = 1</th> </tr> </thead> <tbody> <tr> <td>Robust</td> <td>78.190</td> <td>61.740</td> <td>42.830</td> </tr> <tr> <td>Robust (augmentation)</td> <td>80.560</td> <td>67.200</td> <td>51.140</td> </tr> <tr> <td>Robust (fixed augmentation)</td> <td>81.070</td> <td>67.620</td> <td>51.220</td> </tr> </tbody> </table> <p>Performance gains appear in this case as well. Accuracy on clean data bumps up by 0.51%, while robustness on \(\epsilon=0.5\) and \(\epsilon=1.0\) improves by 0.42% and 0.08%, respectively. The fact that this case sees a consistent, albeit small, improvement in both clean and perturbed-data performance hints at how simply fixing this augmentation may provide a nice bump in existing training methods. It is very much possible that these gains are just coincidental fluctuations in the randomness of model training. Regardless, fixing data-loaders is something that should be done anyway. The goal of these experiments was to try and quantify the impact of improper augmentation. It would be great if someone with sufficient resources could run these experiments on a larger scale to rule out statistical noise.</p> <h2 id="takeaway">Takeaway</h2> <p>Fixing data augmentation can have a non-trivial (and positive) impact when training for robustness. Anyone training robust models (especially with adversarial training, since that is what I tested on) should fix their data-loaders.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/combined.bib"></d-bibliography> <d-article id="bibtex-container" class="related highlight"> For attribution in academic contexts, you can cite this post as <pre id="bibtex-box">
          PLACEHOLDER FOR BIBTEX
        </pre> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Anshuman Suri. Last updated: June 24, 2025. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-news",title:"news",description:"",section:"Navigation",handler:()=>{window.location.href="/news/"}},{id:"nav-talks",title:"talks",description:"",section:"Navigation",handler:()=>{window.location.href="/talks/"}},{id:"nav-service",title:"service",description:"",section:"Navigation",handler:()=>{window.location.href="/service/"}},{id:"post-reassessing-emnlp-2024-s-best-paper-does-divergence-based-calibration-for-membership-inference-attacks-hold-up",title:"Reassessing EMNLP 2024\u2019s Best Paper: Does Divergence-Based Calibration for Membership Inference Attacks Hold...",description:"TL;DR: No. A critical analysis of the EMNLP Best Paper proposing a divergence-based calibration for Membership Inference Attacks (MIAs). We explore its experimental shortcomings, issues with temporally shifted benchmarks, and what this means for machine learning awards.",section:"Posts",handler:()=>{window.location.href="/blog/2024/calibrated-mia/"}},{id:"post-my-submission-to-the-eti-challenge",title:"My submission to the ETI Challenge",description:"Description of my entry to the ETI (Erasing the Invisible) challenge (co-located with NeurIPS) for watermark-removal.",section:"Posts",handler:()=>{window.location.href="/blog/2024/eti-submission/"}},{id:"post-my-submission-to-the-tdc-trojan-detection-challenge",title:"My submission to the TDC Trojan Detection Challenge",description:"Description of my entry to the TDC Trojan Detection challenge (co-located with NeurIPS 2023).",section:"Posts",handler:()=>{window.location.href="/blog/2023/tdc/"}},{id:"post-my-submission-to-the-mico-challenge",title:"My submission to the MICO Challenge",description:"Description of my entry to the MICO challenge (co-located with SaTML) for membership inference that won me the 2nd place on the CIFAR track.",section:"Posts",handler:()=>{window.location.href="/blog/2023/mico/"}},{id:"post-dissecting-distribution-inference",title:"Dissecting Distribution Inference",description:"Describing our work on distribution inference attacks.",section:"Posts",handler:()=>{window.location.href="/blog/2022/ddi/"}},{id:"post-running-scripts-on-rivanna-at-uva",title:"Running scripts on Rivanna at UVA",description:"A tutorial on how to run scripts on Rivanna (SLURM in general) cluster at UVA, along with some tricks.",section:"Posts",handler:()=>{window.location.href="/blog/2022/uva-rivanna/"}},{id:"post-on-the-risks-of-distribution-inference",title:"On the Risks of Distribution Inference",description:"A blog post describing our work on Property Inference attacks.",section:"Posts",handler:()=>{window.location.href="/blog/2021/distr-inf/"}},{id:"post-reassessing-adversarial-training-with-fixed-data-augmentation",title:"Reassessing adversarial training with fixed data augmentation",description:"A recent bug discovery on Pytorch+Numpy got me thinking- how much does this bug impact adversarial robustness?",section:"Posts",handler:()=>{window.location.href="/blog/2021/advrob-aug/"}},{id:"news-passed-my-phd-dissertation-proposal-grin",title:'Passed my PhD Dissertation Proposal <img class="emoji" title=":grin:" alt=":grin:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f601.png" height="20" width="20">',description:"",section:"News"},{id:"news-runner-up-https-microsoft-github-io-mico-for-the-mico-challenge-cifar-track-co-located-with-satml-tada-i-describe-my-approach-here-blog-2023-mico",title:'[Runner-up](https://microsoft.github.io/MICO/) for the MICO challenge (CIFAR track), co-located with SaTML <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> I describe...',description:"",section:"News"},{id:"news-placard-presented-our-work-on-dissecting-distribution-inference-https-arxiv-org-pdf-2212-07591-at-satml-in-raleigh-us",title:'<img class="emoji" title=":placard:" alt=":placard:" src="https://github.githubassets.com/images/icons/emoji/unicode/1faa7.png" height="20" width="20"> Presented our work on [Dissecting Distribution Inference](https://arxiv.org/pdf/2212.07591) at SaTML in Raleigh! <img class="emoji" title=":us:" alt=":us:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f1fa-1f1f8.png" height="20" width="20">...',description:"",section:"News"},{id:"news-received-the-john-a-stankovic-graduate-research-award-https-engineering-virginia-edu-department-computer-science-blogs-cs-department-end-year-award-recipients-2022-2023-from-the-cs-deparment-at-uva-for-excellence-in-research-during-the-2022-2023-academic-year",title:"Received the [John A. Stankovic Graduate Research Award](https://engineering.virginia.edu/department/computer-science/blogs/cs-department-end-year-award-recipients-2022-2023) from the CS deparment at...",description:"",section:"News"},{id:"news-leading-a-reading-group-books-on-causal-learning-https-iamgroot42-github-io-causal-reading-group-23-this-summer-at-uva-along-with-hannah-chen-https-hannahxchen-github-io",title:'Leading a reading group <img class="emoji" title=":books:" alt=":books:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4da.png" height="20" width="20"> on [Causal Learning](https://iamgroot42.github.io/causal-reading-group-23/) this summer at UVA, along...',description:"",section:"News"},{id:"news-received-the-endowed-graduate-fellowship-https-www-linkedin-com-posts-activity-7122237223894192128-shmf-utm-source-share-amp-utm-medium-member-desktop-from-the-school-of-engineering-and-applied-sciences-seas-at-uva-for-2023-24-tada",title:"Received the [Endowed Graduate Fellowship](https://www.linkedin.com/posts/activity-7122237223894192128-SHMF?utm_source=share&utm_medium=member_desktop) from the School of Engineering and Applied Sciences...",description:"",section:"News"},{id:"news-placard-presented-our-work-sok-pitfalls-in-evaluating-black-box-attacks-https-arxiv-org-pdf-2310-17534-pdf-at-satml-in-toronto-canada",title:'<img class="emoji" title=":placard:" alt=":placard:" src="https://github.githubassets.com/images/icons/emoji/unicode/1faa7.png" height="20" width="20"> Presented our work [SoK: Pitfalls in Evaluating Black-Box Attacks](https://arxiv.org/pdf/2310.17534.pdf) at SaTML in...',description:"",section:"News"},{id:"news-ph-done-say-hello-to-dr-suri",title:"Ph-Done! Say hello to Dr. Suri",description:"",section:"News",handler:()=>{window.location.href="/news/ph_done/"}},{id:"news-xiao-https-xiao-zhang-net-presented-our-work-do-parameters-reveal-more-than-loss-for-membership-inference-https-arxiv-org-pdf-2406-11544-at-the-hild-workshop-at-icml-https-sites-google-com-view-hidimlearning-home-in-vienna-austria",title:"[Xiao](https://xiao-zhang.net/) presented our work [Do Parameters Reveal More than Loss for Membership Inference](https://arxiv.org/pdf/2406.11544)...",description:"",section:"News"},{id:"news-started-as-a-postdoc-at-khoury-northeastern-supervised-by-alina-oprea-https-www-khoury-northeastern-edu-home-alina-hello-boston-cityscape",title:"Started as a postdoc at Khoury, Northeastern supervised by [Alina Oprea](https://www.khoury.northeastern.edu/home/alina/). Hello, Boston...",description:"",section:"News"},{id:"news-placard-presented-our-work-do-membership-inference-attacks-work-on-large-language-models-https-arxiv-org-pdf-2402-07841-at-colm-https-colmweb-org-cfp-html-in-philadelphia-sunny",title:'<img class="emoji" title=":placard:" alt=":placard:" src="https://github.githubassets.com/images/icons/emoji/unicode/1faa7.png" height="20" width="20"> Presented our work [Do Membership Inference Attacks Work on Large Language Models?](https://arxiv.org/pdf/2402.07841)...',description:"",section:"News"},{id:"news-newspaper-uva-engineering-covered-a-story-https-engineering-virginia-edu-news-events-news-common-way-test-leaks-large-language-models-may-be-flawed-on-our-work-on-evaluating-membership-inference-attacks-on-large-language-models-https-arxiv-org-pdf-2402-07841",title:'<img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> UVA Engineering [covered a story](https://engineering.virginia.edu/news-events/news/common-way-test-leaks-large-language-models-may-be-flawed) on our work on evaluating [Membership Inference...',description:"",section:"News"},{id:"news-our-blogpost-blog-2024-calibrated-mia-talking-about-critical-flaws-in-the-evaluation-of-a-recent-emnlp-best-paper-https-x-com-emnlpmeeting-status-1857176180128198695-has-been-accepted-to-the-iclr-blogpost-track",title:"Our [blogpost](blog/2024/calibrated-mia/) talking about critical flaws in the evaluation of a recent [EMNLP...",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"talks-bust-in-silhouette-project-personality-chat-intelligent-cloud-conference",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Project Personality Chat. Intelligent Cloud Conference.',description:"",section:"Talks"},{id:"talks-computer-when-models-learn-too-much-inference-privacy-in-theory-and-practice-with-david-evans-microsoft-security-data-science-colloquium",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> When Models Learn Too Much: Inference Privacy in Theory and Practice (with...',description:"",section:"Talks"},{id:"talks-computer-formalizing-distribution-inference-risks-lockheed-martin",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Formalizing Distribution Inference Risks: Lockheed Martin.',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-privacy-in-genomics-https-computingbiology-github-io-s22-class18-cs4501-computational-biology-biological-computing",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> [Privacy in Genomics](https://computingbiology.github.io/s22/class18/). CS4501: Computational Biology / Biological Computing',description:"",section:"Talks"},{id:"talks-computer-distribution-inference-university-of-melbourne",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Distribution Inference. University of Melbourne.',description:"",section:"Talks"},{id:"talks-computer-formalizing-and-estimating-distribution-inference-risks-iiith",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Formalizing and Estimating Distribution Inference Risks: IIITH.',description:"",section:"Talks"},{id:"talks-computer-distribution-inference-new-perspectives-in-data-privacy-cs562-advanced-topics-in-security-privacy-and-machine-learning-uiuc-https-chandrasekaran-group-github-io-courses-cs562-home",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Distribution Inference: New Perspectives in Data Privacy. [CS562 Advanced Topics in Security,...',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-distribution-inference-new-perspectives-in-data-privacy-princeton-https-ece-princeton-edu-events-distribution-inference-new-perspectives-data-privacy",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Distribution Inference: New Perspectives in Data Privacy. [Princeton](https://ece.princeton.edu/events/distribution-inference-new-perspectives-data-privacy).',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-distribution-inference-new-perspectives-in-data-privacy-uva-aiml-seminar-https-uvaml-github-io-pasttalks-2024-02-28",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Distribution Inference: New Perspectives in Data Privacy. [UVA AIML Seminar](https://uvaml.github.io/pasttalks/2024-02-28/).',description:"",section:"Talks"},{id:"talks-computer-do-membership-inference-attacks-work-on-large-language-models-https-drive-google-com-file-d-1vkahsahwkmy4psti7f4k0z26gfakxrv2-view-cohere-for-ai",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> [Do Membership Inference Attacks Work on Large Language Models?](https://drive.google.com/file/d/1vKAHsahwKmy4PsTi7f4K0Z26gfAkXRV2/view) Cohere for AI....',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-do-membership-inference-attacks-work-on-large-language-models-google-research",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Do Membership Inference Attacks Work on Large Language Models? Google Research.',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-do-membership-inference-attacks-work-on-large-language-models-university-of-washington",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Do Membership Inference Attacks Work on Large Language Models? University of Washington....',description:"",section:"Talks"},{id:"talks-computer-do-membership-inference-attacks-work-on-large-language-models-safr-ai-lab-https-sethneel-com-safr-ai-lab-harvard-university",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Do Membership Inference Attacks Work on Large Language Models? [SAFR AI Lab](https://sethneel.com/safr-ai-lab/),...',description:"",section:"Talks"},{id:"talks-computer-do-membership-inference-attacks-work-on-large-language-models-privacy-team-cas-meta-https-research-facebook-com-teams-cas",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Do Membership Inference Attacks Work on Large Language Models? [Privacy Team, CAS,...',description:"",section:"Talks"},{id:"talks-computer-distribution-inference-new-perspectives-in-data-privacy-vector-institute",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Distribution Inference: New Perspectives in Data Privacy. Vector Institute.',description:"",section:"Talks"},{id:"talks-computer-white-box-v-s-black-box-privacy-auditing-for-machine-learning-ai-security-and-privacy-umass-ahmerst-https-aisec-cs-umass-edu",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> White-box v/s Black-box: Privacy Auditing for Machine Learning. [AI Security and Privacy,...',description:"",section:"Talks"},{id:"talks-computer-stealthy-membership-inference-for-retrieval-augmented-generation-fair-ml-university-of-south-florida-https-www-anshumanc-com",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Stealthy Membership Inference for Retrieval-Augmented Generation. [Fair ML, University of South Florida](https://www.anshumanc.com/)....',description:"",section:"Talks"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%61%6E%73.%73%75%72%69@%6E%6F%72%74%68%65%61%73%74%65%72%6E.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=JDp__3wAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/iamgroot42","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/iamgroot42","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/iamgroot42","_blank")}},{id:"socials-bluesky",title:"Bluesky",section:"Socials",handler:()=>{window.open("https://bsky.app/profile/iamgroot42.bsky.social","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>