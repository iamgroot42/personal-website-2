<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <script>let thunk=()=>{let e=e=>e.trim(),t=e=>e.innerText,n=e=>{let t=e.split(" "),n=t.slice(0,-1).join(" ");return[t.at(-1),n]},a=Array.from(document.getElementsByClassName("author")).map(t).map(e).map(n),r=a[0][0],i=(Array.from(document.getElementsByClassName("affiliation")).filter(e=>"P"===e.nodeName).map(t).map(e),"Running scripts on Rivanna at UVA"),o="2022",m="August 14, 2025";{let e=a.map(e=>`${e[0]}, ${e[1]}`).join(" and "),t=`\n@article{${(r+o+i.split(" ").slice(0,3).join("")).replace(" ","").replace(/[\p{P}$+<=>^`|~]/gu,"").toLowerCase().trim()},\n  author = {${e}},\n  title = {${i}},\n  year = {${o}},\n  note = {Accessed ${m}},\n  url  = {${window.location.href}}\n}\n  `.trim();document.getElementById("bibtex-box").innerText=t}};document.addEventListener("readystatechange",function(){"complete"===document.readyState&&thunk()});</script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Running scripts on Rivanna at UVA | Anshuman Suri </title> <meta name="author" content="Anshuman Suri"> <meta name="description" content="A tutorial on how to run scripts on Rivanna (SLURM in general) cluster at UVA, along with some tricks."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%90%BF%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://anshumansuri.com/blog/2022/uva-rivanna/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <d-front-matter> <script async type="text/json">
      {
            "title": "Running scripts on Rivanna at UVA",
            "description": "A tutorial on how to run scripts on Rivanna (SLURM in general) cluster at UVA, along with some tricks.",
            "published": "February 03, 2022",
            "authors": [
              
              {
                "author": "Anshuman Suri",
                "authorURL": "https://anshumansuri.com/",
                "affiliations": [
                  {
                    "name": "University of Virginia",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Anshuman</span> Suri </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news </a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks </a> </li> <li class="nav-item "> <a class="nav-link" href="/service/">service </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Running scripts on Rivanna at UVA</h1> <p>A tutorial on how to run scripts on Rivanna (SLURM in general) cluster at UVA, along with some tricks.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#settings-things-up">Settings things up</a> </div> <div> <a href="#writing-sbatch-scripts">Writing SBATCH scripts</a> </div> <div> <a href="#"></a> </div> <ul> <li> <a href="#submitting-a-job">Submitting a job</a> </li> </ul> <div> <a href="#tips-and-tricks">Tips and Tricks</a> </div> <div> <a href="#"></a> </div> <ul> <li> <a href="#start-time-estimate">Start-Time Estimate</a> </li> <li> <a href="#opening-interactive-sessions">Opening interactive sessions</a> </li> <li> <a href="#adjusting-resources-based-on-job-efficiency">Adjusting resources based on job efficiency</a> </li> <li> <a href="#running-gpu-based-scripts">Running GPU-based scripts</a> </li> </ul> </nav> </d-contents> <h1 id="overview">Overview</h1> <p>Our department has a nice collection of 16 servers, each with 4 GPUs. While this may sound like a lot, the servers are shared across the department and thus fill out pretty fast. We do have a SLURM cluster too, but it’s not as fast (or big enough to run GPU-based jobs via SLURM) as the servers. I recently looked into <a href="https://www.rc.virginia.edu/userinfo/rivanna/overview/" rel="external nofollow noopener" target="_blank">Rivanna</a> after my <a href="https://www.cs.virginia.edu/~evans/" rel="external nofollow noopener" target="_blank">advisor</a> suggested it. I did write some sbatch scripts during my internship at <a href="https://labs.oracle.com/pls/apex/labs/r/labs/intro" rel="external nofollow noopener" target="_blank">Oracle Research Labs</a>, so that definitely came in handy while trying to write wrapper scripts for the Rivanna cluster.</p> <h1 id="settings-things-up">Settings things up</h1> <p>The structure for these environments here is pretty similar to what we have for the CS servers. You can load up specific modules using <code class="language-plaintext highlighter-rouge">module load</code>. Since sbatch files get passed onto in a new bash environment, it’s always a good idea to have all your <code class="language-plaintext highlighter-rouge">module load</code> and other related commands (like <code class="language-plaintext highlighter-rouge">conda activate</code>) in your <code class="language-plaintext highlighter-rouge">.bashrc</code> file so that you don’t have to worry about adding all of them to every sbatch file.</p> <p>For reference, here’s what I added to my <code class="language-plaintext highlighter-rouge">.bashrc</code>:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>module load singularity
module load cudatoolkit/11.0.3-py3.8
module load cuda/11.4.2
module load cudnn/8.2.4.15
module load anaconda/2020.11-py3.8

<span class="c">#Identify whether using Rivanna version (load data accordingly)</span>
<span class="nb">export </span><span class="nv">ISRIVANNA</span><span class="o">=</span>1

<span class="c"># Conda-init related stuff that is auto-populated</span>
conda activate phd <span class="c"># phd is the name of my environment</span>
</code></pre></div></div> <p>The only downside here is that storage is not shared with the other CS servers: you must either commit to using only Rivanna or only CS servers, or make sure you regularly sync your generated code (which is straightforward, thanks to Git) and data (not so trivial).</p> <div class="alert alert-danger" role="alert"> The Rivanna cluster has a cronjob of sorts that <b>deletes files</b> that aren't accessed for more than <b>90 days</b>. </div> <p>There are two storage directories: <code class="language-plaintext highlighter-rouge">/home</code> and <code class="language-plaintext highlighter-rouge">/scratch</code>. The former has a 50GB quota limit with weekly snapshots for backup, while the <code class="language-plaintext highlighter-rouge">/scratch</code> directory has a quota of 10TB/350,000 files (whichever is more). As mentioned on the <a href="https://www.rc.virginia.edu/userinfo/rivanna/storage/" rel="external nofollow noopener" target="_blank">Rivanna Storage</a> page:</p> <blockquote> <p>Slurm jobs run against /home will be slower than those run against /scratch</p> </blockquote> <p>Thus, it is advisable to have all your scripts and data in the <code class="language-plaintext highlighter-rouge">/scratch</code> directory, even your Anaconda environment. You can specify a location for your Conda environment with the <code class="language-plaintext highlighter-rouge">--prefix &lt;PATH&gt;</code> flag while running <code class="language-plaintext highlighter-rouge">conda create</code>.</p> <h1 id="writing-sbatch-scripts">Writing SBATCH scripts</h1> <p>Okay, enough talk! Let’s start with a basic wrapper script- let’s call it <code class="language-plaintext highlighter-rouge">test.sbatch</code>. If you are already familiar with these options and/or just want to use the defaults and get started, feel free to use the template <a href="https://gist.github.com/iamgroot42/2a29141b5cb241aa82aa80809b420437" rel="external nofollow noopener" target="_blank">here</a>.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="c">#SBATCH --ntasks=1</span>
<span class="c">#SBATCH -A uvasrg</span>
<span class="c">#SBATCH --mem=32G</span>
<span class="c">#SBATCH -p gpu</span>
<span class="c">#SBATCH --gres=gpu:rtx2080:1</span>
<span class="c">#SBATCH --cpus-per-task=10</span>
<span class="c">#SBATCH --time=3-00:00:00</span>
<span class="c">#SBATCH --output=logs/%x-%j.out</span>
<span class="c">#SBATCH --error=logs/%x-%j.err</span>

<span class="c"># Your command goes here</span>
<span class="nb">echo</span> <span class="s2">"Parameters were </span><span class="nv">$PARAM1</span><span class="s2"> and </span><span class="nv">$PARAM2</span><span class="s2">"</span>
</code></pre></div></div> <p>Wait, wait, wait! Aren’t the <code class="language-plaintext highlighter-rouge">#SBATCH</code> commands going to get ignored (starts with <code class="language-plaintext highlighter-rouge">#</code>, so it’s got to be a comment, duh?). Well, not really- <code class="language-plaintext highlighter-rouge">#SBATCH</code> commands are treated differently.</p> <h3 id="sbatch---ntasks1"><code class="language-plaintext highlighter-rouge">#SBATCH --ntasks=1</code></h3> <p>This argument specifies the number of tasks you want to run with the given script. In most cases, this will be 1 unless you want parallel execution and will utilize it explicitly via your script.</p> <p>For instance, you could specify <code class="language-plaintext highlighter-rouge">--ntasks=2</code> to run two tasks in parallel:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nb">echo</span> <span class="s2">"Hello there"</span> &amp; 
 <span class="nb">echo</span> <span class="s2">"General Kenobi"</span> &amp;
 <span class="nb">wait</span>
</code></pre></div></div> <p>This can be particularly useful when you have some form of caching, utilize the same file across different scripts, or just like the idea of having all your experiments run on the same physical machine.</p> <h3 id="sbatch--a-uvasrg"><code class="language-plaintext highlighter-rouge">#SBATCH -A uvasrg</code></h3> <p>This option specifies which “allocation” you want to use. As a user at UVA (or SLURM clusters in general), you may be part of one or more allocation groups, which all have their compute budgets. This option ensures that your scripts run on the allocation group you specify. If you happen to be in <a href="https://uvasrg.github.io" rel="external nofollow noopener" target="_blank">UVASRG</a>, this is the option for you!</p> <p>If you’re curious about the compute budget used up/left in your allocation, you can run:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>allocations
</code></pre></div></div> <p>Furthermore, if you’re curious about other members in the same allocation group, you can run:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>allocations <span class="nt">-a</span> &lt;your_group_name&gt;
</code></pre></div></div> <h3 id="sbatch---mem32g"><code class="language-plaintext highlighter-rouge">#SBATCH --mem=32G</code></h3> <p>This is pretty straightforward and lets you specify the total memory (in GBs) you want to allocate to your job. In most cases, 32 or 64 GBs is enough.</p> <div class="alert alert-info" role="alert"> Rivanna has an upper limit of 32 GBs of memory per core, so you'll need to be careful with this. </div> <h3 id="sbatch--p-gpu"><code class="language-plaintext highlighter-rouge">#SBATCH -p gpu</code></h3> <p>This option here specifies which partition you want your scripts to run on. For most users (at least with machine learning), this will be ‘gpu’. You can have a look at all the available partitions <a href="https://www.rc.virginia.edu/userinfo/rivanna/queues/" rel="external nofollow noopener" target="_blank">here</a>.</p> <h3 id="sbatch---gresgpurtx20801"><code class="language-plaintext highlighter-rouge">#SBATCH --gres=gpu:rtx2080:1</code></h3> <p>This option here (the <code class="language-plaintext highlighter-rouge">--gres</code> in general) allows you to specify configurations of the nodes you want to run your scripts on. In this case, the <code class="language-plaintext highlighter-rouge">rtx2080</code> is the name of the GPU card, and <code class="language-plaintext highlighter-rouge">1</code> is the number of cards you want to use. In terms of speed, you might want to prefer v100 over 2080.</p> <p>One thing to note here: there may be times when machines with one type of GPU card are free while others are in use. It might be better to specify the other GPU in such cases instead of waiting for the busy GPU machines to clear up. But how exactly would you know which machines are free and which ones are not?</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sinfo <span class="nt">-o</span> <span class="s2">"%20N %10R %10e %25f %25G %t %C"</span> <span class="nt">-t</span> IDLE,MIX
</code></pre></div></div> <p>This provides information on the status of all machines, their GPU cards (and how many they have), free memory, and free/busy CPU cores. Pretty useful, huh!</p> <h3 id="sbatch---cpus-per-task10"><code class="language-plaintext highlighter-rouge">#SBATCH --cpus-per-task=10</code></h3> <p>This option lets you specify the number of CPUs you require per task in your script. From what I know, Rivanna has an upper limit of 10 per job for the GPU servers, but I’m not too sure about it.</p> <h3 id="sbatch---time3-000000"><code class="language-plaintext highlighter-rouge">#SBATCH --time=3-00:00:00</code></h3> <p>This option here lets you specify an upper limit for your job. SLURM will terminate any jobs after this given time limit (set to a default value much lower than 3 days for Rivanna, from what I remember). We have an upper limit of 3 days, so this pretty much tells SLURM to run the job for as long as possible. If you want to run your job for longer, make sure you cache results so that the re-run can pick up from where the previous job left off.</p> <h3 id="sbatch---outputlogsx-jout"><code class="language-plaintext highlighter-rouge">#SBATCH --output=logs/%x-%j.out</code></h3> <p>These two formats (this and <code class="language-plaintext highlighter-rouge">#SBATCH --error=logs/%x-%j.err</code>) specify the filenames for error and log files. The <code class="language-plaintext highlighter-rouge">%x</code> is the script’s name, and <code class="language-plaintext highlighter-rouge">%j</code> is the job ID.</p> <div class="alert alert-secondary" role="alert"> P.S. You might wanna make sure you have the directory `logs` where you submit your job. </div> <h2 id="submitting-a-job">Submitting a job</h2> <p>There you go! Now that you know what each flag here means, let’s get to submitting the job:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> sbatch <span class="nt">--export</span><span class="o">=</span>ALL,PARAM1<span class="o">=</span><span class="s1">'no'</span>,PARAM2<span class="o">=</span>42 <span class="nt">--job-name</span><span class="o">=</span>try test.sbatch
</code></pre></div></div> <p>Note how we have two additional parameters, <code class="language-plaintext highlighter-rouge">PARAM1</code> and <code class="language-plaintext highlighter-rouge">PARAM2</code>. This is a way for you to pass parameters to your job, which can then be used in your script. Make sure you leave the <code class="language-plaintext highlighter-rouge">ALL</code> in there since this passes on your environment’s predefined variables to the job.</p> <div class="alert alert-danger" role="alert"> Another sidenote (that I found out the weird way) - make sure all your flags and options are specified <b>before</b> the filename of your script. If they aren't, `sbatch` will simply ignore them. </div> <h1 id="job-arrays">Job Arrays</h1> <p>Sometimes you might want to run the same commands inside but with different parameters- maybe you want to run a grid search or generate results for multiple datasets. Instead of creating new sbatch scripts in this case, you can utilize job arrays. This is a way to run multiple jobs with the same configuration but with different parameters.</p> <p>For instance, you could run a job array with the following command:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sbatch <span class="nt">--job-name</span><span class="o">=</span>try test.sbatch <span class="nt">--array</span><span class="o">=</span>0-6
</code></pre></div></div> <p>Note the additional <code class="language-plaintext highlighter-rouge">--array=0-6</code> option. This specifies that you want to run 7 jobs, starting from 0 until 6 (all-inclusive). You could then modify the sbatch script to use different parameters based on the job index:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
<span class="nv">RATIOS</span><span class="o">=(</span>0.2 0.3 0.4 0.5 0.6 0.7 0.8<span class="o">)</span>
<span class="nb">echo</span> <span class="s2">"Running for ratio </span><span class="k">${</span><span class="nv">RATIOS</span><span class="p">[</span><span class="nv">$SLURM_ARRAY_TASK_ID</span><span class="p">]</span><span class="k">}</span><span class="s2">"</span>
...
</code></pre></div></div> <h1 id="tips-and-tricks">Tips and Tricks</h1> <h2 id="start-time-estimate">Start-Time Estimate</h2> <p>Submitted a job, but it’s stuck in <code class="language-plaintext highlighter-rouge">(Priority)</code> or <code class="language-plaintext highlighter-rouge">(Resources)</code>? If you see it’s way too much, you can always default back to some other servers (or change the configuration of your job so that it gets accepted). In cases like these, getting a rough estimate for the start time for your job can be helpful.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> squeue <span class="nt">-u</span> &lt;your_username&gt; <span class="nt">--start</span>
</code></pre></div></div> <p>If you skip the <code class="language-plaintext highlighter-rouge">--start</code> above, you can view all your jobs and relevant information: how long they’ve been running for, their status, etc.</p> <h2 id="opening-interactive-sessions">Opening interactive sessions</h2> <p>Sometimes you may want to test your code out for smaller cases and/or debug, and going to and fro with log files may not be very convenient. You can open an interactive session with your job using the following command:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> ijob <span class="nt">-A</span> uvasrg <span class="nt">-p</span> gpu <span class="nt">--time</span><span class="o">=</span>0-00:30:00 <span class="nt">--gres</span><span class="o">=</span>gpu:rtx2080:1 <span class="nt">--mem</span><span class="o">=</span>8G 
</code></pre></div></div> <p>This command here would open an interactive session (capped at 30 minutes, so that you don’t accidentally leave it on and get charged for it) with your job, run on a machine with the RTX2080 GPU card and an allocation of 8GB memory.</p> <h2 id="adjusting-resources-based-on-job-efficiency">Adjusting resources based on job efficiency</h2> <p>It may so happen that you over-estimate the resources needed for your job, which can lead to higher allocation consumption as well as your scripts running at a later time (because of busy resources). A good starting point is to look at runs of your completed scripts:</p> <div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">you@machine:~$</span><span class="w"> </span>sacct <span class="nt">--starttime</span><span class="o">=</span>2022-02-04 <span class="nt">--endtime</span><span class="o">=</span>2022-02-11 <span class="nt">--state</span> COMPLETED  <span class="nt">-u</span> &lt;your_username&gt;
<span class="go">         JobID    JobName  Partition    Account  AllocCPUS      State ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- -------- 
</span><span class="gp">32259190       job1        gpu     &lt;acc_name&gt;</span><span class="w">         </span>16  COMPLETED      0:0 
<span class="gp">32259191       job2        gpu     &lt;acc_name&gt;</span><span class="w">         </span>16  COMPLETED      0:0 
</code></pre></div></div> <p>This command here, for instance, will give you a list of all completed jobs that started and finished between 4th and 11th February, 2022. You can then pick any jobID that you like and look at its CPU and memory usage efficiency:</p> <div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">you@machine:~$</span><span class="w"> </span>seff 32259190
<span class="go">Job ID: 32259190
Cluster: shen
</span><span class="gp">User/Group: &lt;your_username&gt;</span>/users
<span class="go">State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 16
CPU Utilized: 1-20:54:32
CPU Efficiency: 21.72% of 8-14:47:28 core-walltime
Job Wall-clock time: 12:55:28
Memory Utilized: 5.72 GB
Memory Efficiency: 17.86% of 32.00 GB
</span></code></pre></div></div> <h2 id="running-gpu-based-scripts">Running GPU-based scripts</h2> <p>It’s good practice to specify the GPU card you want to use for your job. Most users might be familiar with <code class="language-plaintext highlighter-rouge">CUDA_VISIBLE_DEVICES</code> and setting this value before their experiments, or via code (in PyTorch, for instance). However, the machines that SLURM runs scripts on have shared GPUs that are visible to each job for some reason. As a result, even if you request one GPU and your job is run on a machine with 8 GPUs, using <code class="language-plaintext highlighter-rouge">export CUDA_VISIBLE_DEVICES=0</code> will, instead of doing nothng (since you’d expecte the visible compute environment to have only one GPU), the job will run on the 1st GPU, even if it’s not the one that’s free.</p> <p>I found this out the hard way (not mentioned on the website documentation, but the support staff were nice enough to tell me about it)- I submitted 8-10 jobs and they were all really slow, since they all got assigned the same machine and the <code class="language-plaintext highlighter-rouge">CUDA_VISIBLE_DEVICES</code> made them run on the same GPU.</p> <div class="alert alert-danger" role="alert"> tl;dr Do not set CUDA_VISIBLE_DEVICES (via envionment variable or within code) for your jobs- SLURM manages that for you. </div> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Anshuman Suri. Last updated: August 14, 2025. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-news",title:"news",description:"",section:"Navigation",handler:()=>{window.location.href="/news/"}},{id:"nav-talks",title:"talks",description:"",section:"Navigation",handler:()=>{window.location.href="/talks/"}},{id:"nav-service",title:"service",description:"",section:"Navigation",handler:()=>{window.location.href="/service/"}},{id:"post-advice-for-working-on-ml-projects",title:"Advice for working on ML projects",description:"Lessons and recommendations based on my experiences working on ML projects.",section:"Posts",handler:()=>{window.location.href="/blog/2025/ml-considerations/"}},{id:"post-reassessing-emnlp-2024-s-best-paper-does-divergence-based-calibration-for-membership-inference-attacks-hold-up",title:"Reassessing EMNLP 2024\u2019s Best Paper: Does Divergence-Based Calibration for Membership Inference Attacks Hold...",description:"TL;DR: No. A critical analysis of the EMNLP Best Paper proposing a divergence-based calibration for Membership Inference Attacks (MIAs). We explore its experimental shortcomings, issues with temporally shifted benchmarks, and what this means for machine learning awards.",section:"Posts",handler:()=>{window.location.href="/blog/2024/calibrated-mia/"}},{id:"post-my-submission-to-the-eti-challenge",title:"My submission to the ETI Challenge",description:"Description of my entry to the ETI (Erasing the Invisible) challenge (co-located with NeurIPS) for watermark-removal.",section:"Posts",handler:()=>{window.location.href="/blog/2024/eti-submission/"}},{id:"post-my-submission-to-the-tdc-trojan-detection-challenge",title:"My submission to the TDC Trojan Detection Challenge",description:"Description of my entry to the TDC Trojan Detection challenge (co-located with NeurIPS 2023).",section:"Posts",handler:()=>{window.location.href="/blog/2023/tdc/"}},{id:"post-my-submission-to-the-mico-challenge",title:"My submission to the MICO Challenge",description:"Description of my entry to the MICO challenge (co-located with SaTML) for membership inference that won me the 2nd place on the CIFAR track.",section:"Posts",handler:()=>{window.location.href="/blog/2023/mico/"}},{id:"post-dissecting-distribution-inference",title:"Dissecting Distribution Inference",description:"Describing our work on distribution inference attacks.",section:"Posts",handler:()=>{window.location.href="/blog/2022/ddi/"}},{id:"post-running-scripts-on-rivanna-at-uva",title:"Running scripts on Rivanna at UVA",description:"A tutorial on how to run scripts on Rivanna (SLURM in general) cluster at UVA, along with some tricks.",section:"Posts",handler:()=>{window.location.href="/blog/2022/uva-rivanna/"}},{id:"post-on-the-risks-of-distribution-inference",title:"On the Risks of Distribution Inference",description:"A blog post describing our work on Property Inference attacks.",section:"Posts",handler:()=>{window.location.href="/blog/2021/distr-inf/"}},{id:"post-reassessing-adversarial-training-with-fixed-data-augmentation",title:"Reassessing adversarial training with fixed data augmentation",description:"A recent bug discovery on Pytorch+Numpy got me thinking- how much does this bug impact adversarial robustness?",section:"Posts",handler:()=>{window.location.href="/blog/2021/advrob-aug/"}},{id:"news-passed-my-phd-dissertation-proposal-grin",title:'Passed my PhD Dissertation Proposal <img class="emoji" title=":grin:" alt=":grin:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f601.png" height="20" width="20">',description:"",section:"News"},{id:"news-runner-up-https-microsoft-github-io-mico-for-the-mico-challenge-cifar-track-co-located-with-satml-tada-i-describe-my-approach-here-blog-2023-mico",title:'[Runner-up](https://microsoft.github.io/MICO/) for the MICO challenge (CIFAR track), co-located with SaTML <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> I describe...',description:"",section:"News"},{id:"news-placard-presented-our-work-on-dissecting-distribution-inference-https-arxiv-org-pdf-2212-07591-at-satml-in-raleigh-us",title:'<img class="emoji" title=":placard:" alt=":placard:" src="https://github.githubassets.com/images/icons/emoji/unicode/1faa7.png" height="20" width="20"> Presented our work on [Dissecting Distribution Inference](https://arxiv.org/pdf/2212.07591) at SaTML in Raleigh! <img class="emoji" title=":us:" alt=":us:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f1fa-1f1f8.png" height="20" width="20">...',description:"",section:"News"},{id:"news-received-the-john-a-stankovic-graduate-research-award-https-engineering-virginia-edu-department-computer-science-blogs-cs-department-end-year-award-recipients-2022-2023-from-the-cs-deparment-at-uva-for-excellence-in-research-during-the-2022-2023-academic-year",title:"Received the [John A. Stankovic Graduate Research Award](https://engineering.virginia.edu/department/computer-science/blogs/cs-department-end-year-award-recipients-2022-2023) from the CS deparment at...",description:"",section:"News"},{id:"news-leading-a-reading-group-books-on-causal-learning-https-iamgroot42-github-io-causal-reading-group-23-this-summer-at-uva-along-with-hannah-chen-https-hannahxchen-github-io",title:'Leading a reading group <img class="emoji" title=":books:" alt=":books:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4da.png" height="20" width="20"> on [Causal Learning](https://iamgroot42.github.io/causal-reading-group-23/) this summer at UVA, along...',description:"",section:"News"},{id:"news-received-the-endowed-graduate-fellowship-https-www-linkedin-com-posts-activity-7122237223894192128-shmf-utm-source-share-amp-utm-medium-member-desktop-from-the-school-of-engineering-and-applied-sciences-seas-at-uva-for-2023-24-tada",title:"Received the [Endowed Graduate Fellowship](https://www.linkedin.com/posts/activity-7122237223894192128-SHMF?utm_source=share&utm_medium=member_desktop) from the School of Engineering and Applied Sciences...",description:"",section:"News"},{id:"news-placard-presented-our-work-sok-pitfalls-in-evaluating-black-box-attacks-https-arxiv-org-pdf-2310-17534-pdf-at-satml-in-toronto-canada",title:'<img class="emoji" title=":placard:" alt=":placard:" src="https://github.githubassets.com/images/icons/emoji/unicode/1faa7.png" height="20" width="20"> Presented our work [SoK: Pitfalls in Evaluating Black-Box Attacks](https://arxiv.org/pdf/2310.17534.pdf) at SaTML in...',description:"",section:"News"},{id:"news-ph-done-say-hello-to-dr-suri",title:"Ph-Done! Say hello to Dr. Suri",description:"",section:"News",handler:()=>{window.location.href="/news/ph_done/"}},{id:"news-xiao-https-xiao-zhang-net-presented-our-work-do-parameters-reveal-more-than-loss-for-membership-inference-https-arxiv-org-pdf-2406-11544-at-the-hild-workshop-at-icml-https-sites-google-com-view-hidimlearning-home-in-vienna-austria",title:"[Xiao](https://xiao-zhang.net/) presented our work [Do Parameters Reveal More than Loss for Membership Inference](https://arxiv.org/pdf/2406.11544)...",description:"",section:"News"},{id:"news-started-as-a-postdoc-at-khoury-northeastern-supervised-by-alina-oprea-https-www-khoury-northeastern-edu-home-alina-hello-boston-cityscape",title:"Started as a postdoc at Khoury, Northeastern supervised by [Alina Oprea](https://www.khoury.northeastern.edu/home/alina/). Hello, Boston...",description:"",section:"News"},{id:"news-placard-presented-our-work-do-membership-inference-attacks-work-on-large-language-models-https-arxiv-org-pdf-2402-07841-at-colm-https-colmweb-org-cfp-html-in-philadelphia-sunny",title:'<img class="emoji" title=":placard:" alt=":placard:" src="https://github.githubassets.com/images/icons/emoji/unicode/1faa7.png" height="20" width="20"> Presented our work [Do Membership Inference Attacks Work on Large Language Models?](https://arxiv.org/pdf/2402.07841)...',description:"",section:"News"},{id:"news-newspaper-uva-engineering-covered-a-story-https-engineering-virginia-edu-news-events-news-common-way-test-leaks-large-language-models-may-be-flawed-on-our-work-on-evaluating-membership-inference-attacks-on-large-language-models-https-arxiv-org-pdf-2402-07841",title:'<img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> UVA Engineering [covered a story](https://engineering.virginia.edu/news-events/news/common-way-test-leaks-large-language-models-may-be-flawed) on our work on evaluating [Membership Inference...',description:"",section:"News"},{id:"news-our-blogpost-blog-2024-calibrated-mia-talking-about-critical-flaws-in-the-evaluation-of-a-recent-emnlp-best-paper-https-x-com-emnlpmeeting-status-1857176180128198695-has-been-accepted-to-the-iclr-blogpost-track",title:"Our [blogpost](blog/2024/calibrated-mia/) talking about critical flaws in the evaluation of a recent [EMNLP...",description:"",section:"News"},{id:"news-awarded-lambda-research-grant-to-work-on-training-time-poisoning-defenses-for-llms-thank-you-lambda-moneybag",title:"Awarded Lambda Research Grant to work on training-time poisoning defenses for LLMs. Thank...",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"talks-bust-in-silhouette-project-personality-chat-intelligent-cloud-conference",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Project Personality Chat. Intelligent Cloud Conference.',description:"",section:"Talks"},{id:"talks-computer-when-models-learn-too-much-inference-privacy-in-theory-and-practice-with-david-evans-microsoft-security-data-science-colloquium",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> When Models Learn Too Much: Inference Privacy in Theory and Practice (with...',description:"",section:"Talks"},{id:"talks-computer-formalizing-distribution-inference-risks-lockheed-martin",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Formalizing Distribution Inference Risks: Lockheed Martin.',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-privacy-in-genomics-https-computingbiology-github-io-s22-class18-cs4501-computational-biology-biological-computing",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> [Privacy in Genomics](https://computingbiology.github.io/s22/class18/). CS4501: Computational Biology / Biological Computing',description:"",section:"Talks"},{id:"talks-computer-distribution-inference-university-of-melbourne",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Distribution Inference. University of Melbourne.',description:"",section:"Talks"},{id:"talks-computer-formalizing-and-estimating-distribution-inference-risks-iiith",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Formalizing and Estimating Distribution Inference Risks: IIITH.',description:"",section:"Talks"},{id:"talks-computer-distribution-inference-new-perspectives-in-data-privacy-cs562-advanced-topics-in-security-privacy-and-machine-learning-uiuc-https-chandrasekaran-group-github-io-courses-cs562-home",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Distribution Inference: New Perspectives in Data Privacy. [CS562 Advanced Topics in Security,...',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-distribution-inference-new-perspectives-in-data-privacy-princeton-https-ece-princeton-edu-events-distribution-inference-new-perspectives-data-privacy",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Distribution Inference: New Perspectives in Data Privacy. [Princeton](https://ece.princeton.edu/events/distribution-inference-new-perspectives-data-privacy).',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-distribution-inference-new-perspectives-in-data-privacy-uva-aiml-seminar-https-uvaml-github-io-pasttalks-2024-02-28",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Distribution Inference: New Perspectives in Data Privacy. [UVA AIML Seminar](https://uvaml.github.io/pasttalks/2024-02-28/).',description:"",section:"Talks"},{id:"talks-computer-do-membership-inference-attacks-work-on-large-language-models-https-drive-google-com-file-d-1vkahsahwkmy4psti7f4k0z26gfakxrv2-view-cohere-for-ai",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> [Do Membership Inference Attacks Work on Large Language Models?](https://drive.google.com/file/d/1vKAHsahwKmy4PsTi7f4K0Z26gfAkXRV2/view) Cohere for AI....',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-do-membership-inference-attacks-work-on-large-language-models-google-research",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Do Membership Inference Attacks Work on Large Language Models? Google Research.',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-do-membership-inference-attacks-work-on-large-language-models-university-of-washington",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Do Membership Inference Attacks Work on Large Language Models? University of Washington....',description:"",section:"Talks"},{id:"talks-computer-do-membership-inference-attacks-work-on-large-language-models-safr-ai-lab-https-sethneel-com-safr-ai-lab-harvard-university",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Do Membership Inference Attacks Work on Large Language Models? [SAFR AI Lab](https://sethneel.com/safr-ai-lab/),...',description:"",section:"Talks"},{id:"talks-computer-do-membership-inference-attacks-work-on-large-language-models-privacy-team-cas-meta-https-research-facebook-com-teams-cas",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Do Membership Inference Attacks Work on Large Language Models? [Privacy Team, CAS,...',description:"",section:"Talks"},{id:"talks-computer-distribution-inference-new-perspectives-in-data-privacy-vector-institute",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Distribution Inference: New Perspectives in Data Privacy. Vector Institute.',description:"",section:"Talks"},{id:"talks-computer-white-box-v-s-black-box-privacy-auditing-for-machine-learning-ai-security-and-privacy-umass-ahmerst-https-aisec-cs-umass-edu",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> White-box v/s Black-box: Privacy Auditing for Machine Learning. [AI Security and Privacy,...',description:"",section:"Talks"},{id:"talks-computer-stealthy-membership-inference-for-retrieval-augmented-generation-fair-ml-university-of-south-florida-https-www-anshumanc-com",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Stealthy Membership Inference for Retrieval-Augmented Generation. [Fair ML, University of South Florida](https://www.anshumanc.com/)....',description:"",section:"Talks"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%61%6E%73.%73%75%72%69@%6E%6F%72%74%68%65%61%73%74%65%72%6E.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=JDp__3wAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/iamgroot42","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/iamgroot42","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/iamgroot42","_blank")}},{id:"socials-bluesky",title:"Bluesky",section:"Socials",handler:()=>{window.open("https://bsky.app/profile/iamgroot42.bsky.social","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>