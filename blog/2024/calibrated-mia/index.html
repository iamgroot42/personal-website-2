<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <script>let thunk=()=>{let e=e=>e.trim(),t=e=>e.innerText,n=e=>{let t=e.split(" "),n=t.slice(0,-1).join(" ");return[t.at(-1),n]},a=Array.from(document.getElementsByClassName("author")).map(t).map(e).map(n),r=a[0][0],i=(Array.from(document.getElementsByClassName("affiliation")).filter(e=>"P"===e.nodeName).map(t).map(e),"Reassessing EMNLP 2024\u2019s Best Paper: Does Divergence-Based Calibration for Membership Inference Attacks Hold Up?"),o="2024",s="June 24, 2025";{let e=a.map(e=>`${e[0]}, ${e[1]}`).join(" and "),t=`\n@article{${(r+o+i.split(" ").slice(0,3).join("")).replace(" ","").replace(/[\p{P}$+<=>^`|~]/gu,"").toLowerCase().trim()},\n  author = {${e}},\n  title = {${i}},\n  year = {${o}},\n  note = {Accessed ${s}},\n  url  = {${window.location.href}}\n}\n  `.trim();document.getElementById("bibtex-box").innerText=t}};document.addEventListener("readystatechange",function(){"complete"===document.readyState&&thunk()});</script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Reassessing EMNLP 2024’s Best Paper: Does Divergence-Based Calibration for Membership Inference Attacks Hold Up? | Anshuman Suri </title> <meta name="author" content="Anshuman Suri"> <meta name="description" content="&lt;strong&gt;TL;DR: No.&lt;/strong&gt;&lt;br&gt; A critical analysis of the EMNLP Best Paper proposing a divergence-based calibration for Membership Inference Attacks (MIAs). We explore its experimental shortcomings, issues with temporally shifted benchmarks, and what this means for machine learning awards."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%90%BF%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://anshumansuri.com/blog/2024/calibrated-mia/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <d-front-matter> <script async type="text/json">
      {
            "title": "Reassessing EMNLP 2024’s Best Paper: Does Divergence-Based Calibration for Membership Inference Attacks Hold Up?",
            "description": "<strong>TL;DR: No.</strong><br> A critical analysis of the EMNLP Best Paper proposing a divergence-based calibration for Membership Inference Attacks (MIAs). We explore its experimental shortcomings, issues with temporally shifted benchmarks, and what this means for machine learning awards.",
            "published": "November 26, 2024",
            "authors": [
              
              {
                "author": "Pratyush Maini",
                "authorURL": "https://pratyushmaini.github.io/",
                "affiliations": [
                  {
                    "name": "Carnegie Mellon Univeristy",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Anshuman Suri",
                "authorURL": "https://anshumansuri.com/",
                "affiliations": [
                  {
                    "name": "Northeastern University",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Anshuman</span> Suri </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news </a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks </a> </li> <li class="nav-item "> <a class="nav-link" href="/service/">service </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Reassessing EMNLP 2024’s Best Paper: Does Divergence-Based Calibration for Membership Inference Attacks Hold Up?</h1> <p><strong>TL;DR: No.</strong><br> A critical analysis of the EMNLP Best Paper proposing a divergence-based calibration for Membership Inference Attacks (MIAs). We explore its experimental shortcomings, issues with temporally shifted benchmarks, and what this means for machine learning awards.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#what-is-membership-inference">What is Membership Inference?</a> </div> <div> <a href="#"></a> </div> <ul> <li> <a href="#what-s-special-about-llms">What's Special about LLMs?</a> </li> </ul> <div> <a href="#method-overview">Method Overview</a> </div> <div> <a href="#experimental-evaluation">Experimental Evaluation</a> </div> <ul> <li> <a href="#true-positive-rate-experiment">True Positive Rate Experiment</a> </li> <li> <a href="#false-positive-rate-experiment">False Positive Rate Experiment</a> </li> </ul> <div> <a href="#the-problem-with-temporally-shifted-benchmarks">The Problem with Temporally Shifted Benchmarks</a> </div> <div> <a href="#"></a> </div> <ul> <li> <a href="#why-these-benchmarks-are-misleading">Why These Benchmarks Are Misleading</a> </li> </ul> <div> <a href="#machine-learning-awards-a-problem-of-incentives">Machine Learning Awards: A Problem of Incentives</a> </div> <div> <a href="#conclusion">Conclusion</a> </div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>At EMNLP 2024, the <a href="https://x.com/emnlpmeeting/status/1857176180128198695/photo/1" rel="external nofollow noopener" target="_blank">Best Paper Award</a> was given to <strong>“Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method”</strong><d-cite key="zhang2024pretraining"></d-cite>. The paper addresses Membership Inference Attacks (MIAs), a key issue in machine learning related to privacy. The authors propose a new calibration method and introduce <strong>PatentMIA</strong>, a benchmark utilizing temporally shifted patent data to validate their approach. The method recalibrates model probabilities using a divergence metric between the outputs of a target model and a token-frequency map (basically a histogram) derived from auxiliary data, claiming improved detection of member and non-member samples.</p> <p>However, upon closer examination, we identified significant shortcomings in both the experimental design and evaluation methodology. The proposed dataset introduces a temporal shift between the distribution of member and non-member data, which can lead to overestimation of the performance of an MIA that may end up distinguishing samples based on the temporal range, and not actual membership.</p> <p>In this post, we critically analyze this shift, and the broader implications of MIA evaluations for models in the wild.</p> <h2 id="what-is-membership-inference">What is Membership Inference?</h2> <p>Membership Inference Attacks (MIAs) are a useful tool in assessing memorization of training data by a model trained on it. Given a model \(D\) samples from some underlying distribution \(\mathcal{D}\) and a model \(M\) trained on \(D\), membership inference <d-cite key="yeom2018privacy"></d-cite> asks the following question:</p> <blockquote> <p>Was some given record \(x\) part of the training dataset \(D\), or just the overall distribution \(\mathcal{D}\)?</p> </blockquote> <p>The underlying distribution \(\mathcal{D}\) is assumed to be large enough to the point where the above test can be reframed as inferring whether \(x \in D\) (via access to \(M\)) or not. In practice, the adversary/auditor starts with some non-member data (data that they know was not part of the training data \(D\), but belongs to the same underlying distribution \(\mathcal{D}\)) and on the basis of some scoring function, generates a distribution of scores for these non-members. A sweep over these values can then yield “thresholds” corresponding to certain false-positive rates (FPRs), which can then be used to evaluate the true-positive rate (TPR) of the approach under consideration.</p> <p>It is important to note here that these non-members should be from the <strong>same</strong> underlying distribution. To better understand why this is important, think of a model trained for the binary classification task of distinguishing images of squirrels and groundhogs <d-footnote>Maybe you want to give nuts to squirrels and vegetables to groundhogs </d-footnote>. For this example, let’s say this particular groundhog image was part of the training data, but the other two weren’t.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/calibrated-mia/groundhog.avif" sizes="95vw"></source> <img src="/assets/img/calibrated-mia/groundhog.avif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/calibrated-mia/squirrel-480.webp 480w,/assets/img/calibrated-mia/squirrel-800.webp 800w,/assets/img/calibrated-mia/squirrel-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/calibrated-mia/squirrel.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/calibrated-mia/llama.webp" sizes="95vw"></source> <img src="/assets/img/calibrated-mia/llama.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>A model will have higher loss on images of llamas, and understandably so since these are images the model did not see at all during training. Using their images would give a clear member/non-member distinction, but would also probably classify <em>any</em> squirrel/groundhog image as a member, even if it wasn’t. As an experimental setup, this is easily enforced when working with standard machine learning models and datasets such as CIFAR-10 and ImageNet, where well-established train/test splits from the same underlying distribution exist.</p> <h3 id="whats-special-about-llms">What’s Special about LLMs?</h3> <p>Because these models are trained on a large scale of data (and in many cases, exact training data is unknown), it is hard to collect data to use as “non-members” which has not been used in the model training <strong>and</strong> is from the same underlying distribution. Early works on membership inference for LLMs resorted to using data generated after a model’s training cutoff <d-cite key="shi2023detecting"></d-cite>, since such data could not have been seen by a model. However, such design choices can introduce implicit distribution shifts <d-cite key="das2024blind,duan2024membership,maini2024llm,meeus2024sok"></d-cite> and give a false sense of membership leakage.</p> <h2 id="method-overview">Method Overview</h2> <p>The proposed method tries to fix a known issue with MIAs: models often fail to properly separate member and non-member samples. To address this, the authors use an auxiliary data-source to compute token-level frequencies, which are then used to recalibrate token-wise model logits. This normalization aims to adjust token-level model probabilities based on their natural frequency or rarity, aligning with membership inference practices such as reference model calibration<d-cite key="carlini2022membership"></d-cite>.</p> <p>They also introduce <strong>PatentMIA</strong>, a benchmark that uses temporally shifted patents as data. The idea is to test whether the model can identify if a patent document was part of its training data or not. While this approach sounds interesting, our experiments suggest that the reported results are influenced by limitations in the benchmark design.</p> <h2 id="experimental-evaluation">Experimental Evaluation</h2> <p>We ran two key experiments to test the paper’s claims: one for true positives and another for false positives.</p> <h3 id="true-positive-rate-experiment">True Positive Rate Experiment</h3> <p>This experiment checks if the method can correctly distinguish member data from non-member data when both are drawn from the <strong>same distribution</strong>. We used train and validation splits from <strong>The Pile</strong> dataset, which ensures there are no temporal or distributional differences between the two sets. Below we report results for the <em>Wikipedia</em> split.</p> <table> <thead> <tr> <th style="text-align: left">Model</th> <th style="text-align: center">AUC</th> <th style="text-align: right">TPR@5%FPR</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><a href="https://huggingface.co/EleutherAI/pythia-6.9b" rel="external nofollow noopener" target="_blank">Pythia-6.9B</a></td> <td style="text-align: center">0.542</td> <td style="text-align: right">0.071</td> </tr> <tr> <td style="text-align: left"><a href="https://huggingface.co/EleutherAI/gpt-neo-125m" rel="external nofollow noopener" target="_blank">GPT-Neo-125M</a></td> <td style="text-align: center">0.492</td> <td style="text-align: right">0.054</td> </tr> <tr> <td style="text-align: left"><a href="https://huggingface.co/EleutherAI/gpt-neox-20b" rel="external nofollow noopener" target="_blank">GPT-NeoX-20B</a></td> <td style="text-align: center">0.600</td> <td style="text-align: right">0.103</td> </tr> </tbody> </table> <p><strong>Result:</strong><br> The method performs only slightly better than the LOSS attack, and remains comparable to most standalone membership inference attacks. For reference, AUC with the baseline LOSS and zlib <d-cite key="carlini2021extracting"></d-cite> attacks for Pythia-6.9B are 0.526 and 0.536 respectively, while it is 0.618 when using a reference-model (Table 12 in <d-cite key="duan2024membership"></d-cite>). Similarly, using LOSS and zlib yield AUCs of 0.563 and 0.572 respectively.</p> <p>Reported improvements in the paper (Table 2 <d-cite key="zhang2024pretraining"></d-cite> showing AUCs of 0.7 and higher) are thus <u>likely due to exploiting differences in the data distribution</u>, rather than actual improvements in detecting membership.</p> <h3 id="false-positive-rate-experiment">False Positive Rate Experiment</h3> <p>Next, we check how often the method falsely identifies data as “member” when it has in fact not be used in the model’s training. To do this, we use the <strong>WikiMIA</strong><d-cite key="shi2023detecting"></d-cite> dataset but replaced the training data with unrelated validation data from the <em>Wikipedia</em> split of <strong>The Pile</strong>. This means that we can say with certainty that the Pythia and GPT-neox models did not train on either split. We follow the experimental setup of in Section 3 of <d-cite key="maini2024llm"></d-cite> for this analysis.</p> <p><strong>Result:</strong><br> Below we report results for the <em>Wikipedia</em> split. Note that in this setting, a score closer to 0.5 is better since both splits are non-members.</p> <table> <thead> <tr> <th style="text-align: left">Model</th> <th style="text-align: center">AUC for DC-PDD <d-cite key="zhang2024pretraining"></d-cite> </th> <th style="text-align: right">AUC for LOSS <d-cite key="carlini2021extracting"></d-cite> </th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><a href="https://huggingface.co/EleutherAI/pythia-6.9b" rel="external nofollow noopener" target="_blank">Pythia-6.9B</a></td> <td style="text-align: center">0.667</td> <td style="text-align: right">0.636</td> </tr> <tr> <td style="text-align: left"><a href="https://huggingface.co/EleutherAI/gpt-neo-125m" rel="external nofollow noopener" target="_blank">GPT-Neo-125M</a></td> <td style="text-align: center">0.689</td> <td style="text-align: right">0.671</td> </tr> <tr> <td style="text-align: left"><a href="https://huggingface.co/EleutherAI/gpt-neox-20b" rel="external nofollow noopener" target="_blank">GPT-Neox-20b</a></td> <td style="text-align: center">0.637</td> <td style="text-align: right">0.656</td> </tr> </tbody> </table> <p>The method flags a high number of false positives. It frequently identifies non-member data as part of the training set, suggesting that the attack was was reliant on temporal or distribution artifacts rather than truly detecting membership.</p> <h2 id="the-problem-with-temporally-shifted-benchmarks">The Problem with Temporally Shifted Benchmarks</h2> <p>The introduction of <strong>PatentMIA</strong> highlights a broader problem with MIA research: benchmarks that rely on temporal shifts <d-cite key="meeus2024did,shi2023detecting,dubinski2024towards,ko2023practical"></d-cite>. These benchmarks often make it easy for attack models to exploit simple artifacts, like whether a document contains terms that didn’t exist during training (e.g., “COVID-19” or “Tesla Model Y”). This creates an illusion of success but doesn’t address the real challenge of membership inference.</p> <h3 id="why-these-benchmarks-are-misleading">Why These Benchmarks Are Misleading</h3> <p>The issues with temporally shifted benchmarks are not new. Several prior works have already established the dangers of using such benchmarks:</p> <ol> <li> <strong>Spurious Patterns</strong>: Temporal shifts introduce artifacts that are easily exploitable by attack models. As noted by Duan et al. <d-cite key="duan2024membership"></d-cite>, temporal markers (e.g., “COVID-19” or recent events) allow models to cheat by detecting new concepts rather than true membership.</li> <li> <strong>Misleading Evaluations</strong>: Maini et al. <d-cite key="maini2024llm"></d-cite> show how temporal shifts can inflate the perceived success of MIAs, even when no meaningful membership inference occurs.</li> <li> <strong>Blind Baselines Work Better</strong>: Das et al. <d-cite key="das2024blind"></d-cite> demonstrate that blind baselines often outperform sophisticated MIAs on temporally shifted datasets, highlighting how these benchmarks fail to test real inference ability.</li> </ol> <p>Despite these well-established issues, the EMNLP Best Paper continues to rely on temporally shifted data like <strong>PatentMIA</strong> for its evaluations. This undermines the robustness of its claims and contributes little to advancing membership inference research.</p> <hr> <h2 id="machine-learning-awards-a-problem-of-incentives">Machine Learning Awards: A Problem of Incentives</h2> <p>This situation raises important questions about the role of awards in machine learning research.</p> <ol> <li> <strong>Do Awards Encourage Rushed Work?</strong> Highlighting work with known flaws, like relying on misleading benchmarks, can discourage researchers from investing time in more rigorous evaluations.</li> <li> <strong>Harming the Field</strong>: Awards that celebrate flawed work set a bad precedent and can mislead the community into thinking these methods are the gold standard.</li> <li> <strong>Losing Credibility</strong>: Over time, the reputation of awards themselves suffers, as researchers may start viewing them as less meaningful.</li> </ol> <p>This is a growing problem in machine learning research, where not only acceptance but even awards are constantly under <a href="https://www.reddit.com/r/MachineLearning/comments/w4ooph/d_icml_2022_outstanding_paper_awards/" rel="external nofollow noopener" target="_blank">scrutiny</a> for their <a href="https://parameterfree.com/2023/08/30/yet-another-icml-award-fiasco/" rel="external nofollow noopener" target="_blank">soundness</a>, let alone their contribution. If awards are to truly highlight excellence, they must emphasize thoroughness, reproducibility, and robustness over surface-level novelty.</p> <h2 id="conclusion">Conclusion</h2> <p>The EMNLP 2024 Best Paper sought to address a pressing challenge in membership inference but falls short under careful scrutiny. The proposed method fails both in distinguishing members and non-members under rigorous conditions and in avoiding false positives when the data is untrained. Furthermore, its reliance on <strong>PatentMIA</strong> exemplifies a larger issue with using temporally shifted benchmarks to claim progress.</p> <p>For the field to advance meaningfully, greater emphasis must be placed on rigorous evaluation practices. Awards should reflect this by rewarding work with robust and thorough evaluations, rather than methods that (knowingly or otherwise) exploit well-known flaws in evaluation practices. Only then can we ensure that the field moves forward in a meaningful way.</p> <h4 id="acknowledgements">Acknowledgements</h4> <p>We would like to thank <a href="https://www.zacharylipton.com/" rel="external nofollow noopener" target="_blank">Zack Lipton</a> and <a href="https://zicokolter.com/" rel="external nofollow noopener" target="_blank">Zico Kolter</a> for their helpful feedback on the draft and for referring us to Nicholas’s <d-cite key="carlini2019ami"></d-cite> example of good criticism.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/combined.bib"></d-bibliography> <d-article id="bibtex-container" class="related highlight"> For attribution in academic contexts, you can cite this post as <pre id="bibtex-box">
          PLACEHOLDER FOR BIBTEX
        </pre> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Anshuman Suri. Last updated: June 24, 2025. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-news",title:"news",description:"",section:"Navigation",handler:()=>{window.location.href="/news/"}},{id:"nav-talks",title:"talks",description:"",section:"Navigation",handler:()=>{window.location.href="/talks/"}},{id:"nav-service",title:"service",description:"",section:"Navigation",handler:()=>{window.location.href="/service/"}},{id:"post-reassessing-emnlp-2024-s-best-paper-does-divergence-based-calibration-for-membership-inference-attacks-hold-up",title:"Reassessing EMNLP 2024\u2019s Best Paper: Does Divergence-Based Calibration for Membership Inference Attacks Hold...",description:"TL;DR: No. A critical analysis of the EMNLP Best Paper proposing a divergence-based calibration for Membership Inference Attacks (MIAs). We explore its experimental shortcomings, issues with temporally shifted benchmarks, and what this means for machine learning awards.",section:"Posts",handler:()=>{window.location.href="/blog/2024/calibrated-mia/"}},{id:"post-my-submission-to-the-eti-challenge",title:"My submission to the ETI Challenge",description:"Description of my entry to the ETI (Erasing the Invisible) challenge (co-located with NeurIPS) for watermark-removal.",section:"Posts",handler:()=>{window.location.href="/blog/2024/eti-submission/"}},{id:"post-my-submission-to-the-tdc-trojan-detection-challenge",title:"My submission to the TDC Trojan Detection Challenge",description:"Description of my entry to the TDC Trojan Detection challenge (co-located with NeurIPS 2023).",section:"Posts",handler:()=>{window.location.href="/blog/2023/tdc/"}},{id:"post-my-submission-to-the-mico-challenge",title:"My submission to the MICO Challenge",description:"Description of my entry to the MICO challenge (co-located with SaTML) for membership inference that won me the 2nd place on the CIFAR track.",section:"Posts",handler:()=>{window.location.href="/blog/2023/mico/"}},{id:"post-dissecting-distribution-inference",title:"Dissecting Distribution Inference",description:"Describing our work on distribution inference attacks.",section:"Posts",handler:()=>{window.location.href="/blog/2022/ddi/"}},{id:"post-running-scripts-on-rivanna-at-uva",title:"Running scripts on Rivanna at UVA",description:"A tutorial on how to run scripts on Rivanna (SLURM in general) cluster at UVA, along with some tricks.",section:"Posts",handler:()=>{window.location.href="/blog/2022/uva-rivanna/"}},{id:"post-on-the-risks-of-distribution-inference",title:"On the Risks of Distribution Inference",description:"A blog post describing our work on Property Inference attacks.",section:"Posts",handler:()=>{window.location.href="/blog/2021/distr-inf/"}},{id:"post-reassessing-adversarial-training-with-fixed-data-augmentation",title:"Reassessing adversarial training with fixed data augmentation",description:"A recent bug discovery on Pytorch+Numpy got me thinking- how much does this bug impact adversarial robustness?",section:"Posts",handler:()=>{window.location.href="/blog/2021/advrob-aug/"}},{id:"news-passed-my-phd-dissertation-proposal-grin",title:'Passed my PhD Dissertation Proposal <img class="emoji" title=":grin:" alt=":grin:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f601.png" height="20" width="20">',description:"",section:"News"},{id:"news-runner-up-https-microsoft-github-io-mico-for-the-mico-challenge-cifar-track-co-located-with-satml-tada-i-describe-my-approach-here-blog-2023-mico",title:'[Runner-up](https://microsoft.github.io/MICO/) for the MICO challenge (CIFAR track), co-located with SaTML <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> I describe...',description:"",section:"News"},{id:"news-placard-presented-our-work-on-dissecting-distribution-inference-https-arxiv-org-pdf-2212-07591-at-satml-in-raleigh-us",title:'<img class="emoji" title=":placard:" alt=":placard:" src="https://github.githubassets.com/images/icons/emoji/unicode/1faa7.png" height="20" width="20"> Presented our work on [Dissecting Distribution Inference](https://arxiv.org/pdf/2212.07591) at SaTML in Raleigh! <img class="emoji" title=":us:" alt=":us:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f1fa-1f1f8.png" height="20" width="20">...',description:"",section:"News"},{id:"news-received-the-john-a-stankovic-graduate-research-award-https-engineering-virginia-edu-department-computer-science-blogs-cs-department-end-year-award-recipients-2022-2023-from-the-cs-deparment-at-uva-for-excellence-in-research-during-the-2022-2023-academic-year",title:"Received the [John A. Stankovic Graduate Research Award](https://engineering.virginia.edu/department/computer-science/blogs/cs-department-end-year-award-recipients-2022-2023) from the CS deparment at...",description:"",section:"News"},{id:"news-leading-a-reading-group-books-on-causal-learning-https-iamgroot42-github-io-causal-reading-group-23-this-summer-at-uva-along-with-hannah-chen-https-hannahxchen-github-io",title:'Leading a reading group <img class="emoji" title=":books:" alt=":books:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4da.png" height="20" width="20"> on [Causal Learning](https://iamgroot42.github.io/causal-reading-group-23/) this summer at UVA, along...',description:"",section:"News"},{id:"news-received-the-endowed-graduate-fellowship-https-www-linkedin-com-posts-activity-7122237223894192128-shmf-utm-source-share-amp-utm-medium-member-desktop-from-the-school-of-engineering-and-applied-sciences-seas-at-uva-for-2023-24-tada",title:"Received the [Endowed Graduate Fellowship](https://www.linkedin.com/posts/activity-7122237223894192128-SHMF?utm_source=share&utm_medium=member_desktop) from the School of Engineering and Applied Sciences...",description:"",section:"News"},{id:"news-placard-presented-our-work-sok-pitfalls-in-evaluating-black-box-attacks-https-arxiv-org-pdf-2310-17534-pdf-at-satml-in-toronto-canada",title:'<img class="emoji" title=":placard:" alt=":placard:" src="https://github.githubassets.com/images/icons/emoji/unicode/1faa7.png" height="20" width="20"> Presented our work [SoK: Pitfalls in Evaluating Black-Box Attacks](https://arxiv.org/pdf/2310.17534.pdf) at SaTML in...',description:"",section:"News"},{id:"news-ph-done-say-hello-to-dr-suri",title:"Ph-Done! Say hello to Dr. Suri",description:"",section:"News",handler:()=>{window.location.href="/news/ph_done/"}},{id:"news-xiao-https-xiao-zhang-net-presented-our-work-do-parameters-reveal-more-than-loss-for-membership-inference-https-arxiv-org-pdf-2406-11544-at-the-hild-workshop-at-icml-https-sites-google-com-view-hidimlearning-home-in-vienna-austria",title:"[Xiao](https://xiao-zhang.net/) presented our work [Do Parameters Reveal More than Loss for Membership Inference](https://arxiv.org/pdf/2406.11544)...",description:"",section:"News"},{id:"news-started-as-a-postdoc-at-khoury-northeastern-supervised-by-alina-oprea-https-www-khoury-northeastern-edu-home-alina-hello-boston-cityscape",title:"Started as a postdoc at Khoury, Northeastern supervised by [Alina Oprea](https://www.khoury.northeastern.edu/home/alina/). Hello, Boston...",description:"",section:"News"},{id:"news-placard-presented-our-work-do-membership-inference-attacks-work-on-large-language-models-https-arxiv-org-pdf-2402-07841-at-colm-https-colmweb-org-cfp-html-in-philadelphia-sunny",title:'<img class="emoji" title=":placard:" alt=":placard:" src="https://github.githubassets.com/images/icons/emoji/unicode/1faa7.png" height="20" width="20"> Presented our work [Do Membership Inference Attacks Work on Large Language Models?](https://arxiv.org/pdf/2402.07841)...',description:"",section:"News"},{id:"news-newspaper-uva-engineering-covered-a-story-https-engineering-virginia-edu-news-events-news-common-way-test-leaks-large-language-models-may-be-flawed-on-our-work-on-evaluating-membership-inference-attacks-on-large-language-models-https-arxiv-org-pdf-2402-07841",title:'<img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> UVA Engineering [covered a story](https://engineering.virginia.edu/news-events/news/common-way-test-leaks-large-language-models-may-be-flawed) on our work on evaluating [Membership Inference...',description:"",section:"News"},{id:"news-our-blogpost-blog-2024-calibrated-mia-talking-about-critical-flaws-in-the-evaluation-of-a-recent-emnlp-best-paper-https-x-com-emnlpmeeting-status-1857176180128198695-has-been-accepted-to-the-iclr-blogpost-track",title:"Our [blogpost](blog/2024/calibrated-mia/) talking about critical flaws in the evaluation of a recent [EMNLP...",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"talks-bust-in-silhouette-project-personality-chat-intelligent-cloud-conference",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Project Personality Chat. Intelligent Cloud Conference.',description:"",section:"Talks"},{id:"talks-computer-when-models-learn-too-much-inference-privacy-in-theory-and-practice-with-david-evans-microsoft-security-data-science-colloquium",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> When Models Learn Too Much: Inference Privacy in Theory and Practice (with...',description:"",section:"Talks"},{id:"talks-computer-formalizing-distribution-inference-risks-lockheed-martin",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Formalizing Distribution Inference Risks: Lockheed Martin.',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-privacy-in-genomics-https-computingbiology-github-io-s22-class18-cs4501-computational-biology-biological-computing",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> [Privacy in Genomics](https://computingbiology.github.io/s22/class18/). CS4501: Computational Biology / Biological Computing',description:"",section:"Talks"},{id:"talks-computer-distribution-inference-university-of-melbourne",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Distribution Inference. University of Melbourne.',description:"",section:"Talks"},{id:"talks-computer-formalizing-and-estimating-distribution-inference-risks-iiith",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Formalizing and Estimating Distribution Inference Risks: IIITH.',description:"",section:"Talks"},{id:"talks-computer-distribution-inference-new-perspectives-in-data-privacy-cs562-advanced-topics-in-security-privacy-and-machine-learning-uiuc-https-chandrasekaran-group-github-io-courses-cs562-home",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Distribution Inference: New Perspectives in Data Privacy. [CS562 Advanced Topics in Security,...',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-distribution-inference-new-perspectives-in-data-privacy-princeton-https-ece-princeton-edu-events-distribution-inference-new-perspectives-data-privacy",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Distribution Inference: New Perspectives in Data Privacy. [Princeton](https://ece.princeton.edu/events/distribution-inference-new-perspectives-data-privacy).',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-distribution-inference-new-perspectives-in-data-privacy-uva-aiml-seminar-https-uvaml-github-io-pasttalks-2024-02-28",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Distribution Inference: New Perspectives in Data Privacy. [UVA AIML Seminar](https://uvaml.github.io/pasttalks/2024-02-28/).',description:"",section:"Talks"},{id:"talks-computer-do-membership-inference-attacks-work-on-large-language-models-https-drive-google-com-file-d-1vkahsahwkmy4psti7f4k0z26gfakxrv2-view-cohere-for-ai",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> [Do Membership Inference Attacks Work on Large Language Models?](https://drive.google.com/file/d/1vKAHsahwKmy4PsTi7f4K0Z26gfAkXRV2/view) Cohere for AI....',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-do-membership-inference-attacks-work-on-large-language-models-google-research",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Do Membership Inference Attacks Work on Large Language Models? Google Research.',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-do-membership-inference-attacks-work-on-large-language-models-university-of-washington",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Do Membership Inference Attacks Work on Large Language Models? University of Washington....',description:"",section:"Talks"},{id:"talks-computer-do-membership-inference-attacks-work-on-large-language-models-safr-ai-lab-https-sethneel-com-safr-ai-lab-harvard-university",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Do Membership Inference Attacks Work on Large Language Models? [SAFR AI Lab](https://sethneel.com/safr-ai-lab/),...',description:"",section:"Talks"},{id:"talks-computer-do-membership-inference-attacks-work-on-large-language-models-privacy-team-cas-meta-https-research-facebook-com-teams-cas",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Do Membership Inference Attacks Work on Large Language Models? [Privacy Team, CAS,...',description:"",section:"Talks"},{id:"talks-computer-distribution-inference-new-perspectives-in-data-privacy-vector-institute",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Distribution Inference: New Perspectives in Data Privacy. Vector Institute.',description:"",section:"Talks"},{id:"talks-computer-white-box-v-s-black-box-privacy-auditing-for-machine-learning-ai-security-and-privacy-umass-ahmerst-https-aisec-cs-umass-edu",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> White-box v/s Black-box: Privacy Auditing for Machine Learning. [AI Security and Privacy,...',description:"",section:"Talks"},{id:"talks-computer-stealthy-membership-inference-for-retrieval-augmented-generation-fair-ml-university-of-south-florida-https-www-anshumanc-com",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Stealthy Membership Inference for Retrieval-Augmented Generation. [Fair ML, University of South Florida](https://www.anshumanc.com/)....',description:"",section:"Talks"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%61%6E%73.%73%75%72%69@%6E%6F%72%74%68%65%61%73%74%65%72%6E.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=JDp__3wAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/iamgroot42","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/iamgroot42","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/iamgroot42","_blank")}},{id:"socials-bluesky",title:"Bluesky",section:"Socials",handler:()=>{window.open("https://bsky.app/profile/iamgroot42.bsky.social","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>