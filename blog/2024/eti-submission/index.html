<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <script>let thunk=()=>{let e=e=>e.trim(),t=e=>e.innerText,n=e=>{let t=e.split(" "),n=t.slice(0,-1).join(" ");return[t.at(-1),n]},a=Array.from(document.getElementsByClassName("author")).map(t).map(e).map(n),r=a[0][0],i=(Array.from(document.getElementsByClassName("affiliation")).filter(e=>"P"===e.nodeName).map(t).map(e),"My submission to the ETI Challenge"),o="2024",l="June 30, 2025";{let e=a.map(e=>`${e[0]}, ${e[1]}`).join(" and "),t=`\n@article{${(r+o+i.split(" ").slice(0,3).join("")).replace(" ","").replace(/[\p{P}$+<=>^`|~]/gu,"").toLowerCase().trim()},\n  author = {${e}},\n  title = {${i}},\n  year = {${o}},\n  note = {Accessed ${l}},\n  url  = {${window.location.href}}\n}\n  `.trim();document.getElementById("bibtex-box").innerText=t}};document.addEventListener("readystatechange",function(){"complete"===document.readyState&&thunk()});</script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> My submission to the ETI Challenge | Anshuman Suri </title> <meta name="author" content="Anshuman Suri"> <meta name="description" content="Description of my entry to the ETI (Erasing the Invisible) challenge (co-located with NeurIPS) for watermark-removal."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%90%BF%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://anshumansuri.com/blog/2024/eti-submission/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <d-front-matter> <script async type="text/json">
      {
            "title": "My submission to the ETI Challenge",
            "description": "Description of my entry to the ETI (Erasing the Invisible) challenge (co-located with NeurIPS) for watermark-removal.",
            "published": "November 12, 2024",
            "authors": [
              
              {
                "author": "Anshuman Suri",
                "authorURL": "https://anshumansuri.com/",
                "affiliations": [
                  {
                    "name": "Northeastern University",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Anshuman</span> Suri </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news </a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks </a> </li> <li class="nav-item "> <a class="nav-link" href="/service/">service </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>My submission to the ETI Challenge</h1> <p>Description of my entry to the ETI (Erasing the Invisible) challenge (co-located with NeurIPS) for watermark-removal.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#adversarial-rinsing">Adversarial Rinsing</a> </div> <div> <a href="#"></a> </div> <ul> <li> <a href="#generating-adversarial-perturbations">Generating Adversarial Perturbations</a> </li> <li> <a href="#augmentations-for-robustness">Augmentations for Robustness</a> </li> <li> <a href="#generative-models">Generative Models</a> </li> </ul> <div> <a href="#what-didn-t-work">What didn’t work?</a> </div> <div> <a href="#takeaways">Takeaways</a> </div> </nav> </d-contents> <p>This post describes an approach developed for the <a href="https://erasinginvisible.github.io/" rel="external nofollow noopener" target="_blank">Erasing the Invisible</a> challenge at NeurIPS 2024. My method combined “rinsing” with adversarial techniques, designed for both the black-box and beige-box competition tracks. Although my solution didn’t secure a top spot, I saw potential in the methodology and wanted to document it to possibly aid future research and development in this area.</p> <h2 id="adversarial-rinsing">Adversarial Rinsing</h2> <p>The central idea behind my approach is blending “rinsing”<d-cite key="an2024waves"></d-cite> with adversarial perturbations. “Rinsing” here means passing an image through a diffusion model multiple times, intending to erode watermarks present in the input. For adversarial examples, I used the SMI$^2$FGSM<d-cite key="wang2022enhancing"></d-cite> attack because of its success with transfer-based attacks<d-cite key="suya2024sok"></d-cite>. The objective of these adversarial perturbations is to disrupt the latent space representation of the image, aiming to dislodge any potential latent-space watermarks.</p> <h3 id="generating-adversarial-perturbations">Generating Adversarial Perturbations</h3> <p>I used a joint loss that maximizes the separation of the perturbed image’s embedding from the original in two ways:</p> <ul> <li> <strong>Embedding Space Distance</strong>: A loss that combines norm-distance and cosine-distance for better embedding separation.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MSEandCosine</span><span class="p">(</span><span class="n">ch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="bp">...</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="n">mse_loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">mse</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="c1"># Flatten to compute cosine similarity
</span>        <span class="n">csn_loss</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="nf">csn</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">target</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="n">target</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># Combined Loss
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">mse_loss</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">csn_loss</span>
        <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></div> <ul> <li> <strong>Image Quality Loss</strong>: This component uses differentiable metrics like PSNR, SSIM, LPIPS, aesthetics, and artifacts scores. By optimizing this loss, my aim was to preserve the original image quality while removing the watermark.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">NormalizedImageQuality</span><span class="p">(</span><span class="n">ch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="bp">...</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
            Output here is generated image, target is original image
        </span><span class="sh">"""</span>
        <span class="n">outputs_aesthetics</span><span class="p">,</span> <span class="n">outputs_artifacts</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_compute_aesthetics_and_artifacts_scores</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">final_score</span> <span class="o">=</span> <span class="o">-</span><span class="mf">4.5e-2</span> <span class="o">*</span> <span class="n">outputs_aesthetics</span> <span class="o">+</span> <span class="mf">1.44e-1</span> <span class="o">*</span> <span class="n">outputs_artifacts</span>
        <span class="k">return</span> <span class="n">final_score</span>

        <span class="n">lpips_score</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_lpips</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="n">psnr_score</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_psnr</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="n">ssim_score</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_ssim</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="n">outputs_aesthetics</span><span class="p">,</span> <span class="n">outputs_artifacts</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_compute_aesthetics_and_artifacts_scores</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

        <span class="c1"># Differentiable NMI is too slow, so ignoring it for now
</span>        <span class="c1"># nmi_score = differentiable_nmi(output, target)
</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">target_aesthetics</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">target_aesthetics</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">target_artifacts</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_compute_aesthetics_and_artifacts_scores</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>

        <span class="n">delta_aesthetics</span> <span class="o">=</span> <span class="n">outputs_aesthetics</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">target_aesthetics</span>
        <span class="n">delta_artifacts</span> <span class="o">=</span> <span class="n">outputs_artifacts</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">target_artifacts</span>

        <span class="c1"># Differentiable metrics!
</span>        <span class="n">weighted_scores</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">psnr_score</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.22e-3</span><span class="p">),</span> <span class="c1"># PSNR
</span>            <span class="p">(</span><span class="n">ssim_score</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.13e-1</span><span class="p">),</span> <span class="c1"># SSIM
</span>            <span class="p">(</span><span class="n">lpips_score</span><span class="p">,</span> <span class="mf">3.41e-1</span><span class="p">),</span> <span class="c1"># LPIPS
</span>            <span class="p">(</span><span class="n">delta_aesthetics</span><span class="p">,</span> <span class="mf">4.5e-2</span><span class="p">),</span> <span class="c1"># Delta-Aesthetics
</span>            <span class="p">(</span><span class="n">delta_artifacts</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.44e-1</span><span class="p">),</span> <span class="c1"># Delta-Artifacts
</span>        <span class="p">]</span>

        <span class="c1"># Aggregate weighted scores
</span>        <span class="n">final_score</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">([</span><span class="n">score</span> <span class="o">*</span> <span class="n">weight</span> <span class="k">for</span> <span class="n">score</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">weighted_scores</span><span class="p">])</span>

        <span class="c1"># Want to be close to zero
</span>        <span class="k">return</span> <span class="n">ch</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">final_score</span><span class="p">)</span>
</code></pre></div></div> <p>The optimization then proceeds with a series of augmentations (described below), with an $L_\infty$ norm constraint on the added perturbation. During experimentation, I also tried minimizing detection by watermark-detection models like WAVES but found it degraded performance.<d-footnote>I didn't play around too much with the hyper-parameters in my algorithm. Maybe some hyper-parameter tuning could help?</d-footnote></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="bp">...</span>
<span class="sh">"</span><span class="s">stable_sig</span><span class="sh">"</span><span class="p">:</span> <span class="p">(</span><span class="nc">ClassificationWrapper</span><span class="p">(</span><span class="n">stable_sig</span><span class="p">),</span> <span class="sh">"</span><span class="s">classify</span><span class="sh">"</span><span class="p">),</span>
<span class="sh">"</span><span class="s">tree_ring</span><span class="sh">"</span><span class="p">:</span> <span class="p">(</span><span class="nc">ClassificationWrapper</span><span class="p">(</span><span class="n">tree_ring</span><span class="p">),</span> <span class="sh">"</span><span class="s">classify</span><span class="sh">"</span><span class="p">),</span>
<span class="sh">"</span><span class="s">stegastamp</span><span class="sh">"</span><span class="p">:</span> <span class="p">(</span><span class="nc">ClassificationWrapper</span><span class="p">(</span><span class="n">stegastamp</span><span class="p">),</span> <span class="sh">"</span><span class="s">classify</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <h3 id="augmentations-for-robustness">Augmentations for Robustness</h3> <p>To enhance the effectiveness of the attack, a diverse set of differentiable augmentations are integrated into SMI$^2$FGSM. These augmentations are chosen to closely match the kind of augmentations usually used in watermark-insertion algorithms: <code class="language-plaintext highlighter-rouge">Random crop, Gaussian blur, Gaussian noise, JPEG compression, Noise in the FFT domain, Rotation, Motion Blur, Random brightness, Random contrast, Random hue, Horizontal flips</code>. I additionally used Mixup using a set of clean images. To avoid the attack overfitting to a specific augmentation, I randomly sampled from the set of possible augmentations at each iteration.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">transformation_functions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">random_crop</span><span class="p">,</span>
        <span class="n">gaussian_blur</span><span class="p">,</span>
        <span class="bp">...</span>
        <span class="n">mixup</span>
    <span class="p">]</span>
    <span class="c1"># Randomly pick one of the transformation functions
</span>    <span class="n">random_transform</span> <span class="o">=</span> <span class="n">transformation_functions</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">transformation_functions</span><span class="p">))]</span>
</code></pre></div></div> <p>I also sample the hyper-parameters for each of these augmentations from a wide range of values to avoid potential overfitting.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">motion_blur</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="n">angle</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">175</span><span class="p">)</span>
  <span class="n">direction</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
  <span class="k">return</span> <span class="n">kornia</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="nf">motion_blur</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="n">direction</span><span class="p">,</span> <span class="n">angle</span><span class="o">=</span><span class="n">angle</span><span class="p">,</span> <span class="n">border_type</span><span class="o">=</span><span class="sh">'</span><span class="s">constant</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <h3 id="generative-models">Generative Models</h3> <p>Empirical observations during implementation revealed that the <code class="language-plaintext highlighter-rouge">waves</code> and <code class="language-plaintext highlighter-rouge">openai/consistency-decoder</code> generative models yielded the best results. Flipping their order or adding another diffusion/generative models only made the final image worse, since multiple rinsing runs were presumably degrading image quality.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_class_scaled_logits</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">features</span><span class="p">).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="n">num_classes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">outputs</span><span class="p">):</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">item</span><span class="p">()</span>
        <span class="n">wanted</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="n">label</span><span class="p">]</span>
        <span class="n">not_wanted</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">delete</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">label</span><span class="p">)]</span>
        <span class="n">values</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">wanted</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">not_wanted</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
</code></pre></div></div> <h2 id="what-didnt-work">What didn’t work?</h2> <p>A ton of things! I experimented with a lot of compression algorithms, adding noise to images, and various combinations of all of these methods. I also tried adding adversarial perturbations generated using some Imagenet classifier (as a proxy for perturbations that could shift the latent space in favor of avoiding watermark detection). None of them worked, with most of them retaining most of their watermarks. To be honest this did surprise me a bit- stepping into this field I did not realize that these image watermarks could be so robust. I also tried my adversarial-rinse approach, but without “rinsing” - using watermark-detection models as my target models, with varying number of iterations. While that does work to some extent, its performance is nowhere close to that when rinsing is introduced. While the converse is also true, rinsing by itself proved to be much more useful than only adversarial perturbations.</p> <h2 id="takeaways">Takeaways</h2> <p>This was definitely a very fun and interesting challenge! I got to learn more about the cat-and-mouse game of watermark insertion and removal, and play around with diffusion models. While the competition itself encourages a joint score of image degradation and low detection rates, I can see a more practical adversary caring way more about the former - after all, one can always try multiple times to bypass filtering (if, say, uploading to OSM platforms) while minimizing image degradation.</p> <p>My solution is available here: <a href="https://github.com/iamgroot42/adversarial-rinsing" rel="external nofollow noopener" target="_blank">https://github.com/iamgroot42/adversarial-rinsing</a></p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/combined.bib"></d-bibliography> <d-article id="bibtex-container" class="related highlight"> For attribution in academic contexts, you can cite this post as <pre id="bibtex-box">
          PLACEHOLDER FOR BIBTEX
        </pre> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Anshuman Suri. Last updated: June 30, 2025. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-news",title:"news",description:"",section:"Navigation",handler:()=>{window.location.href="/news/"}},{id:"nav-talks",title:"talks",description:"",section:"Navigation",handler:()=>{window.location.href="/talks/"}},{id:"nav-service",title:"service",description:"",section:"Navigation",handler:()=>{window.location.href="/service/"}},{id:"post-reassessing-emnlp-2024-s-best-paper-does-divergence-based-calibration-for-membership-inference-attacks-hold-up",title:"Reassessing EMNLP 2024\u2019s Best Paper: Does Divergence-Based Calibration for Membership Inference Attacks Hold...",description:"TL;DR: No. A critical analysis of the EMNLP Best Paper proposing a divergence-based calibration for Membership Inference Attacks (MIAs). We explore its experimental shortcomings, issues with temporally shifted benchmarks, and what this means for machine learning awards.",section:"Posts",handler:()=>{window.location.href="/blog/2024/calibrated-mia/"}},{id:"post-ml-considerations",title:"Ml Considerations",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/ml-considerations/"}},{id:"post-my-submission-to-the-eti-challenge",title:"My submission to the ETI Challenge",description:"Description of my entry to the ETI (Erasing the Invisible) challenge (co-located with NeurIPS) for watermark-removal.",section:"Posts",handler:()=>{window.location.href="/blog/2024/eti-submission/"}},{id:"post-my-submission-to-the-tdc-trojan-detection-challenge",title:"My submission to the TDC Trojan Detection Challenge",description:"Description of my entry to the TDC Trojan Detection challenge (co-located with NeurIPS 2023).",section:"Posts",handler:()=>{window.location.href="/blog/2023/tdc/"}},{id:"post-my-submission-to-the-mico-challenge",title:"My submission to the MICO Challenge",description:"Description of my entry to the MICO challenge (co-located with SaTML) for membership inference that won me the 2nd place on the CIFAR track.",section:"Posts",handler:()=>{window.location.href="/blog/2023/mico/"}},{id:"post-dissecting-distribution-inference",title:"Dissecting Distribution Inference",description:"Describing our work on distribution inference attacks.",section:"Posts",handler:()=>{window.location.href="/blog/2022/ddi/"}},{id:"post-running-scripts-on-rivanna-at-uva",title:"Running scripts on Rivanna at UVA",description:"A tutorial on how to run scripts on Rivanna (SLURM in general) cluster at UVA, along with some tricks.",section:"Posts",handler:()=>{window.location.href="/blog/2022/uva-rivanna/"}},{id:"post-on-the-risks-of-distribution-inference",title:"On the Risks of Distribution Inference",description:"A blog post describing our work on Property Inference attacks.",section:"Posts",handler:()=>{window.location.href="/blog/2021/distr-inf/"}},{id:"post-reassessing-adversarial-training-with-fixed-data-augmentation",title:"Reassessing adversarial training with fixed data augmentation",description:"A recent bug discovery on Pytorch+Numpy got me thinking- how much does this bug impact adversarial robustness?",section:"Posts",handler:()=>{window.location.href="/blog/2021/advrob-aug/"}},{id:"news-passed-my-phd-dissertation-proposal-grin",title:'Passed my PhD Dissertation Proposal <img class="emoji" title=":grin:" alt=":grin:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f601.png" height="20" width="20">',description:"",section:"News"},{id:"news-runner-up-https-microsoft-github-io-mico-for-the-mico-challenge-cifar-track-co-located-with-satml-tada-i-describe-my-approach-here-blog-2023-mico",title:'[Runner-up](https://microsoft.github.io/MICO/) for the MICO challenge (CIFAR track), co-located with SaTML <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> I describe...',description:"",section:"News"},{id:"news-placard-presented-our-work-on-dissecting-distribution-inference-https-arxiv-org-pdf-2212-07591-at-satml-in-raleigh-us",title:'<img class="emoji" title=":placard:" alt=":placard:" src="https://github.githubassets.com/images/icons/emoji/unicode/1faa7.png" height="20" width="20"> Presented our work on [Dissecting Distribution Inference](https://arxiv.org/pdf/2212.07591) at SaTML in Raleigh! <img class="emoji" title=":us:" alt=":us:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f1fa-1f1f8.png" height="20" width="20">...',description:"",section:"News"},{id:"news-received-the-john-a-stankovic-graduate-research-award-https-engineering-virginia-edu-department-computer-science-blogs-cs-department-end-year-award-recipients-2022-2023-from-the-cs-deparment-at-uva-for-excellence-in-research-during-the-2022-2023-academic-year",title:"Received the [John A. Stankovic Graduate Research Award](https://engineering.virginia.edu/department/computer-science/blogs/cs-department-end-year-award-recipients-2022-2023) from the CS deparment at...",description:"",section:"News"},{id:"news-leading-a-reading-group-books-on-causal-learning-https-iamgroot42-github-io-causal-reading-group-23-this-summer-at-uva-along-with-hannah-chen-https-hannahxchen-github-io",title:'Leading a reading group <img class="emoji" title=":books:" alt=":books:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4da.png" height="20" width="20"> on [Causal Learning](https://iamgroot42.github.io/causal-reading-group-23/) this summer at UVA, along...',description:"",section:"News"},{id:"news-received-the-endowed-graduate-fellowship-https-www-linkedin-com-posts-activity-7122237223894192128-shmf-utm-source-share-amp-utm-medium-member-desktop-from-the-school-of-engineering-and-applied-sciences-seas-at-uva-for-2023-24-tada",title:"Received the [Endowed Graduate Fellowship](https://www.linkedin.com/posts/activity-7122237223894192128-SHMF?utm_source=share&utm_medium=member_desktop) from the School of Engineering and Applied Sciences...",description:"",section:"News"},{id:"news-placard-presented-our-work-sok-pitfalls-in-evaluating-black-box-attacks-https-arxiv-org-pdf-2310-17534-pdf-at-satml-in-toronto-canada",title:'<img class="emoji" title=":placard:" alt=":placard:" src="https://github.githubassets.com/images/icons/emoji/unicode/1faa7.png" height="20" width="20"> Presented our work [SoK: Pitfalls in Evaluating Black-Box Attacks](https://arxiv.org/pdf/2310.17534.pdf) at SaTML in...',description:"",section:"News"},{id:"news-ph-done-say-hello-to-dr-suri",title:"Ph-Done! Say hello to Dr. Suri",description:"",section:"News",handler:()=>{window.location.href="/news/ph_done/"}},{id:"news-xiao-https-xiao-zhang-net-presented-our-work-do-parameters-reveal-more-than-loss-for-membership-inference-https-arxiv-org-pdf-2406-11544-at-the-hild-workshop-at-icml-https-sites-google-com-view-hidimlearning-home-in-vienna-austria",title:"[Xiao](https://xiao-zhang.net/) presented our work [Do Parameters Reveal More than Loss for Membership Inference](https://arxiv.org/pdf/2406.11544)...",description:"",section:"News"},{id:"news-started-as-a-postdoc-at-khoury-northeastern-supervised-by-alina-oprea-https-www-khoury-northeastern-edu-home-alina-hello-boston-cityscape",title:"Started as a postdoc at Khoury, Northeastern supervised by [Alina Oprea](https://www.khoury.northeastern.edu/home/alina/). Hello, Boston...",description:"",section:"News"},{id:"news-placard-presented-our-work-do-membership-inference-attacks-work-on-large-language-models-https-arxiv-org-pdf-2402-07841-at-colm-https-colmweb-org-cfp-html-in-philadelphia-sunny",title:'<img class="emoji" title=":placard:" alt=":placard:" src="https://github.githubassets.com/images/icons/emoji/unicode/1faa7.png" height="20" width="20"> Presented our work [Do Membership Inference Attacks Work on Large Language Models?](https://arxiv.org/pdf/2402.07841)...',description:"",section:"News"},{id:"news-newspaper-uva-engineering-covered-a-story-https-engineering-virginia-edu-news-events-news-common-way-test-leaks-large-language-models-may-be-flawed-on-our-work-on-evaluating-membership-inference-attacks-on-large-language-models-https-arxiv-org-pdf-2402-07841",title:'<img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> UVA Engineering [covered a story](https://engineering.virginia.edu/news-events/news/common-way-test-leaks-large-language-models-may-be-flawed) on our work on evaluating [Membership Inference...',description:"",section:"News"},{id:"news-our-blogpost-blog-2024-calibrated-mia-talking-about-critical-flaws-in-the-evaluation-of-a-recent-emnlp-best-paper-https-x-com-emnlpmeeting-status-1857176180128198695-has-been-accepted-to-the-iclr-blogpost-track",title:"Our [blogpost](blog/2024/calibrated-mia/) talking about critical flaws in the evaluation of a recent [EMNLP...",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"talks-bust-in-silhouette-project-personality-chat-intelligent-cloud-conference",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Project Personality Chat. Intelligent Cloud Conference.',description:"",section:"Talks"},{id:"talks-computer-when-models-learn-too-much-inference-privacy-in-theory-and-practice-with-david-evans-microsoft-security-data-science-colloquium",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> When Models Learn Too Much: Inference Privacy in Theory and Practice (with...',description:"",section:"Talks"},{id:"talks-computer-formalizing-distribution-inference-risks-lockheed-martin",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Formalizing Distribution Inference Risks: Lockheed Martin.',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-privacy-in-genomics-https-computingbiology-github-io-s22-class18-cs4501-computational-biology-biological-computing",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> [Privacy in Genomics](https://computingbiology.github.io/s22/class18/). CS4501: Computational Biology / Biological Computing',description:"",section:"Talks"},{id:"talks-computer-distribution-inference-university-of-melbourne",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Distribution Inference. University of Melbourne.',description:"",section:"Talks"},{id:"talks-computer-formalizing-and-estimating-distribution-inference-risks-iiith",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Formalizing and Estimating Distribution Inference Risks: IIITH.',description:"",section:"Talks"},{id:"talks-computer-distribution-inference-new-perspectives-in-data-privacy-cs562-advanced-topics-in-security-privacy-and-machine-learning-uiuc-https-chandrasekaran-group-github-io-courses-cs562-home",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Distribution Inference: New Perspectives in Data Privacy. [CS562 Advanced Topics in Security,...',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-distribution-inference-new-perspectives-in-data-privacy-princeton-https-ece-princeton-edu-events-distribution-inference-new-perspectives-data-privacy",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Distribution Inference: New Perspectives in Data Privacy. [Princeton](https://ece.princeton.edu/events/distribution-inference-new-perspectives-data-privacy).',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-distribution-inference-new-perspectives-in-data-privacy-uva-aiml-seminar-https-uvaml-github-io-pasttalks-2024-02-28",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Distribution Inference: New Perspectives in Data Privacy. [UVA AIML Seminar](https://uvaml.github.io/pasttalks/2024-02-28/).',description:"",section:"Talks"},{id:"talks-computer-do-membership-inference-attacks-work-on-large-language-models-https-drive-google-com-file-d-1vkahsahwkmy4psti7f4k0z26gfakxrv2-view-cohere-for-ai",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> [Do Membership Inference Attacks Work on Large Language Models?](https://drive.google.com/file/d/1vKAHsahwKmy4PsTi7f4K0Z26gfAkXRV2/view) Cohere for AI....',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-do-membership-inference-attacks-work-on-large-language-models-google-research",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Do Membership Inference Attacks Work on Large Language Models? Google Research.',description:"",section:"Talks"},{id:"talks-bust-in-silhouette-do-membership-inference-attacks-work-on-large-language-models-university-of-washington",title:'<img class="emoji" title=":bust_in_silhouette:" alt=":bust_in_silhouette:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f464.png" height="20" width="20"> Do Membership Inference Attacks Work on Large Language Models? University of Washington....',description:"",section:"Talks"},{id:"talks-computer-do-membership-inference-attacks-work-on-large-language-models-safr-ai-lab-https-sethneel-com-safr-ai-lab-harvard-university",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Do Membership Inference Attacks Work on Large Language Models? [SAFR AI Lab](https://sethneel.com/safr-ai-lab/),...',description:"",section:"Talks"},{id:"talks-computer-do-membership-inference-attacks-work-on-large-language-models-privacy-team-cas-meta-https-research-facebook-com-teams-cas",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Do Membership Inference Attacks Work on Large Language Models? [Privacy Team, CAS,...',description:"",section:"Talks"},{id:"talks-computer-distribution-inference-new-perspectives-in-data-privacy-vector-institute",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Distribution Inference: New Perspectives in Data Privacy. Vector Institute.',description:"",section:"Talks"},{id:"talks-computer-white-box-v-s-black-box-privacy-auditing-for-machine-learning-ai-security-and-privacy-umass-ahmerst-https-aisec-cs-umass-edu",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> White-box v/s Black-box: Privacy Auditing for Machine Learning. [AI Security and Privacy,...',description:"",section:"Talks"},{id:"talks-computer-stealthy-membership-inference-for-retrieval-augmented-generation-fair-ml-university-of-south-florida-https-www-anshumanc-com",title:'<img class="emoji" title=":computer:" alt=":computer:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bb.png" height="20" width="20"> Stealthy Membership Inference for Retrieval-Augmented Generation. [Fair ML, University of South Florida](https://www.anshumanc.com/)....',description:"",section:"Talks"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%61%6E%73.%73%75%72%69@%6E%6F%72%74%68%65%61%73%74%65%72%6E.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=JDp__3wAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/iamgroot42","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/iamgroot42","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/iamgroot42","_blank")}},{id:"socials-bluesky",title:"Bluesky",section:"Socials",handler:()=>{window.open("https://bsky.app/profile/iamgroot42.bsky.social","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>